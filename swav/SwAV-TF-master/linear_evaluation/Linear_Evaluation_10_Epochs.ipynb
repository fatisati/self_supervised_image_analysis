{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Linear Evaluation on Flower Dataset",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/SwAV-TF/blob/master/linear_evaluation/Linear_Evaluation_10_Epochs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mQhyBFsMg_ye"
      },
      "source": [
        "# Imports and Setups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v8fMXBGWztKi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "65079ba7-9fe4-444d-9701-6dcb293c2035"
      },
      "source": [
        "!git clone https://github.com/ayulockin/SwAV-TF.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SwAV-TF'...\n",
            "remote: Enumerating objects: 179, done.\u001b[K\n",
            "remote: Counting objects: 100% (179/179), done.\u001b[K\n",
            "remote: Compressing objects: 100% (168/168), done.\u001b[K\n",
            "remote: Total 179 (delta 80), reused 26 (delta 11), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (179/179), 13.73 MiB | 16.16 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1O-8mYyD0CiP",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('SwAV-TF/utils')\n",
        "\n",
        "import multicrop_dataset\n",
        "import architecture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R1c99jQL0KMr",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "from imutils import paths\n",
        "\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)\n",
        "\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ch7kShibnJv-"
      },
      "source": [
        "#### W&B - Experiment Tracking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SaUmsxfJnGvz",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ATFdYM6TmxuQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "9534fc2a-01ac-4669-864d-2f59548bc80f"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://app.wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Not authenticated.  Copy a key from https://app.wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "API Key: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7eaekTr10Yzn"
      },
      "source": [
        "#### Restoring model weights from GCS Bucket - Model trained for 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LROY2Mrn0wpY",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import get_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZiEZfPfG0TeL",
        "colab": {}
      },
      "source": [
        "feature_backbone_urlpath = \"https://storage.googleapis.com/swav-tf/feature_backbone_10_epochs.h5\"\n",
        "prototype_urlpath = \"https://storage.googleapis.com/swav-tf/projection_prototype_10_epochs.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7pEVJ4Y70isN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "7db50430-5430-45eb-8cc8-e63f81269679"
      },
      "source": [
        "feature_backbone_weights = get_file('swav_feature_weights', feature_backbone_urlpath)\n",
        "prototype_weights = get_file('swav_prototype_projection_weights', prototype_urlpath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/swav-tf/feature_backbone_10_epochs.h5\n",
            "94584832/94583160 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/swav-tf/projection_prototype_10_epochs.h5\n",
            "17907712/17900192 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vnhWEo8_12FK"
      },
      "source": [
        "#### Dataset gathering and preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BAOhOFMs110h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "ea899d34-5b4c-48b0-80ab-f86fa531a7ba"
      },
      "source": [
        "# Gather Flowers dataset\n",
        "train_ds, validation_ds = tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split=[\"train[:85%]\", \"train[85%:]\"],\n",
        "    as_supervised=True\n",
        ")\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "@tf.function\n",
        "def scale_resize_image(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, (224, 224)) # Resizing to highest resolution used while training swav\n",
        "    return (image, label)\n",
        "\n",
        "training_ds = (\n",
        "    train_ds\n",
        "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "testing_ds = (\n",
        "    validation_ds\n",
        "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset tf_flowers is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset tf_flowers/3.0.0 (download: 218.21 MiB, generated: Unknown size, total: 218.21 MiB) to /root/tensorflow_datasets/tf_flowers/3.0.0...\u001b[0m\n",
            "\u001b[1mDataset tf_flowers downloaded and prepared to /root/tensorflow_datasets/tf_flowers/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eqOBLHJa5Ztp"
      },
      "source": [
        "#### Get SwAV architecture and Build Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Znqofzfr46-4",
        "colab": {}
      },
      "source": [
        "def get_linear_classifier(alpha=1e-6):\n",
        "    # input placeholder\n",
        "    inputs = Input(shape=(224, 224, 3))\n",
        "    # get swav baseline model architecture\n",
        "    feature_backbone = architecture.get_resnet_backbone()\n",
        "    # load trained weights\n",
        "    feature_backbone.load_weights(feature_backbone_weights)\n",
        "    feature_backbone.trainable = False\n",
        "\n",
        "    x = feature_backbone(inputs, training=False)\n",
        "    outputs = Dense(5, activation=\"softmax\", \n",
        "                    kernel_regularizer=tf.keras.regularizers.L2(alpha))(x)\n",
        "    linear_model = Model(inputs, outputs)\n",
        "\n",
        "    return linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qtt4jmzzxe8Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "51612ced-28a3-4803-f09a-13a52a167b03"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = get_linear_classifier()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "functional_1 (Functional)    (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 10245     \n",
            "=================================================================\n",
            "Total params: 23,597,957\n",
            "Trainable params: 10,245\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I0o5LHV0pCPu"
      },
      "source": [
        "#### Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vECu62eyCdut",
        "colab": {}
      },
      "source": [
        "# Early Stopping to prevent overfitting\n",
        "early_stopper =a tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, verbose=2, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rp1fJIEYpFIC"
      },
      "source": [
        "# Training Linear Classifier - Without Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CutzK-izvyyV"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RArUvFToDJKn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57ab4c17-4d6e-4986-8085-e3f9f6ee7f63"
      },
      "source": [
        "# get model and compile\n",
        "tf.keras.backend.clear_session()\n",
        "model = get_linear_classifier(alpha=1e-6)\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer=\"adam\")\n",
        "\n",
        "# initialize wandb run\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train \n",
        "history = model.fit(training_ds,\n",
        "                 validation_data=(testing_ds),\n",
        "                 epochs=100,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "functional_1 (Functional)    (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 10245     \n",
            "=================================================================\n",
            "Total params: 23,597,957\n",
            "Trainable params: 10,245\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/3nwdhc5n\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/3nwdhc5n</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 14s 1s/step - loss: 2.2577 - acc: 0.2333 - val_loss: 1.9785 - val_acc: 0.2673\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 12s 960ms/step - loss: 1.7493 - acc: 0.2804 - val_loss: 1.7935 - val_acc: 0.2873\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 12s 957ms/step - loss: 1.6388 - acc: 0.3000 - val_loss: 1.7007 - val_acc: 0.2691\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 1.5845 - acc: 0.3067 - val_loss: 1.6058 - val_acc: 0.3000\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 12s 911ms/step - loss: 1.5634 - acc: 0.3212 - val_loss: 1.5892 - val_acc: 0.2945\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 12s 914ms/step - loss: 1.5399 - acc: 0.3324 - val_loss: 1.5834 - val_acc: 0.3091\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 12s 923ms/step - loss: 1.5349 - acc: 0.3372 - val_loss: 1.5685 - val_acc: 0.3109\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 1.5230 - acc: 0.3455 - val_loss: 1.5583 - val_acc: 0.3145\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 12s 938ms/step - loss: 1.5117 - acc: 0.3510 - val_loss: 1.5488 - val_acc: 0.3200\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 12s 931ms/step - loss: 1.5043 - acc: 0.3522 - val_loss: 1.5461 - val_acc: 0.3255\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 12s 919ms/step - loss: 1.4934 - acc: 0.3551 - val_loss: 1.5389 - val_acc: 0.3345\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 12s 891ms/step - loss: 1.4860 - acc: 0.3628 - val_loss: 1.5389 - val_acc: 0.3291\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 12s 929ms/step - loss: 1.4785 - acc: 0.3654 - val_loss: 1.5353 - val_acc: 0.3273\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 1.4699 - acc: 0.3708 - val_loss: 1.5325 - val_acc: 0.3455\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 12s 936ms/step - loss: 1.4635 - acc: 0.3756 - val_loss: 1.5306 - val_acc: 0.3436\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 12s 932ms/step - loss: 1.4558 - acc: 0.3804 - val_loss: 1.5259 - val_acc: 0.3509\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 1.4491 - acc: 0.3827 - val_loss: 1.5231 - val_acc: 0.3509\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 12s 945ms/step - loss: 1.4425 - acc: 0.3849 - val_loss: 1.5194 - val_acc: 0.3527\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 12s 925ms/step - loss: 1.4360 - acc: 0.3907 - val_loss: 1.5156 - val_acc: 0.3491\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 12s 926ms/step - loss: 1.4299 - acc: 0.3939 - val_loss: 1.5127 - val_acc: 0.3509\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 1.4238 - acc: 0.3929 - val_loss: 1.5094 - val_acc: 0.3509\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 12s 938ms/step - loss: 1.4181 - acc: 0.3958 - val_loss: 1.5065 - val_acc: 0.3564\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 12s 932ms/step - loss: 1.4124 - acc: 0.3968 - val_loss: 1.5036 - val_acc: 0.3655\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 12s 931ms/step - loss: 1.4068 - acc: 0.3990 - val_loss: 1.5006 - val_acc: 0.3673\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 12s 922ms/step - loss: 1.4014 - acc: 0.4029 - val_loss: 1.4977 - val_acc: 0.3655\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 12s 933ms/step - loss: 1.3960 - acc: 0.4058 - val_loss: 1.4947 - val_acc: 0.3636\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 1.3907 - acc: 0.4077 - val_loss: 1.4917 - val_acc: 0.3618\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 12s 931ms/step - loss: 1.3855 - acc: 0.4103 - val_loss: 1.4887 - val_acc: 0.3636\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 12s 925ms/step - loss: 1.3804 - acc: 0.4151 - val_loss: 1.4858 - val_acc: 0.3600\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 12s 933ms/step - loss: 1.3754 - acc: 0.4173 - val_loss: 1.4831 - val_acc: 0.3618\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 12s 935ms/step - loss: 1.3705 - acc: 0.4202 - val_loss: 1.4805 - val_acc: 0.3600\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 12s 933ms/step - loss: 1.3658 - acc: 0.4234 - val_loss: 1.4782 - val_acc: 0.3636\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 12s 932ms/step - loss: 1.3612 - acc: 0.4272 - val_loss: 1.4761 - val_acc: 0.3673\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 12s 929ms/step - loss: 1.3568 - acc: 0.4288 - val_loss: 1.4742 - val_acc: 0.3673\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 12s 932ms/step - loss: 1.3525 - acc: 0.4276 - val_loss: 1.4726 - val_acc: 0.3691\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 12s 940ms/step - loss: 1.3484 - acc: 0.4295 - val_loss: 1.4711 - val_acc: 0.3709\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 12s 936ms/step - loss: 1.3445 - acc: 0.4330 - val_loss: 1.4698 - val_acc: 0.3709\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.3407 - acc: 0.4353 - val_loss: 1.4685 - val_acc: 0.3709\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 12s 931ms/step - loss: 1.3370 - acc: 0.4385 - val_loss: 1.4671 - val_acc: 0.3691\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.3335 - acc: 0.4436 - val_loss: 1.4656 - val_acc: 0.3655\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.3301 - acc: 0.4458 - val_loss: 1.4639 - val_acc: 0.3691\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.3268 - acc: 0.4471 - val_loss: 1.4618 - val_acc: 0.3691\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 12s 929ms/step - loss: 1.3236 - acc: 0.4497 - val_loss: 1.4593 - val_acc: 0.3691\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 12s 934ms/step - loss: 1.3205 - acc: 0.4494 - val_loss: 1.4564 - val_acc: 0.3727\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 1.3174 - acc: 0.4484 - val_loss: 1.4530 - val_acc: 0.3745\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 1.3144 - acc: 0.4532 - val_loss: 1.4494 - val_acc: 0.3782\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.3114 - acc: 0.4567 - val_loss: 1.4454 - val_acc: 0.3836\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 1.3085 - acc: 0.4554 - val_loss: 1.4412 - val_acc: 0.3891\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 12s 926ms/step - loss: 1.3056 - acc: 0.4593 - val_loss: 1.4369 - val_acc: 0.3891\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 12s 925ms/step - loss: 1.3028 - acc: 0.4603 - val_loss: 1.4326 - val_acc: 0.3873\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 12s 932ms/step - loss: 1.2998 - acc: 0.4647 - val_loss: 1.4284 - val_acc: 0.3909\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 12s 936ms/step - loss: 1.2969 - acc: 0.4683 - val_loss: 1.4243 - val_acc: 0.3909\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 12s 933ms/step - loss: 1.2938 - acc: 0.4699 - val_loss: 1.4205 - val_acc: 0.3855\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.2906 - acc: 0.4696 - val_loss: 1.4172 - val_acc: 0.3873\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 12s 938ms/step - loss: 1.2872 - acc: 0.4744 - val_loss: 1.4142 - val_acc: 0.3836\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 12s 931ms/step - loss: 1.2835 - acc: 0.4763 - val_loss: 1.4119 - val_acc: 0.3855\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.2797 - acc: 0.4782 - val_loss: 1.4100 - val_acc: 0.3818\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 12s 931ms/step - loss: 1.2756 - acc: 0.4788 - val_loss: 1.4085 - val_acc: 0.3818\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 12s 931ms/step - loss: 1.2715 - acc: 0.4801 - val_loss: 1.4073 - val_acc: 0.3764\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.2672 - acc: 0.4824 - val_loss: 1.4063 - val_acc: 0.3764\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 12s 925ms/step - loss: 1.2630 - acc: 0.4853 - val_loss: 1.4053 - val_acc: 0.3764\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 12s 924ms/step - loss: 1.2589 - acc: 0.4885 - val_loss: 1.4042 - val_acc: 0.3745\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 12s 936ms/step - loss: 1.2549 - acc: 0.4907 - val_loss: 1.4031 - val_acc: 0.3709\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.2512 - acc: 0.4920 - val_loss: 1.4019 - val_acc: 0.3764\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 12s 925ms/step - loss: 1.2476 - acc: 0.4942 - val_loss: 1.4007 - val_acc: 0.3764\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 1.2442 - acc: 0.4971 - val_loss: 1.3994 - val_acc: 0.3800\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 12s 933ms/step - loss: 1.2409 - acc: 0.4981 - val_loss: 1.3982 - val_acc: 0.3836\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 12s 934ms/step - loss: 1.2377 - acc: 0.4997 - val_loss: 1.3969 - val_acc: 0.3836\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 1.2346 - acc: 0.5016 - val_loss: 1.3955 - val_acc: 0.3855\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 12s 923ms/step - loss: 1.2316 - acc: 0.5022 - val_loss: 1.3941 - val_acc: 0.3891\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 1.2287 - acc: 0.5019 - val_loss: 1.3928 - val_acc: 0.3891\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 12s 924ms/step - loss: 1.2258 - acc: 0.5022 - val_loss: 1.3914 - val_acc: 0.3909\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.2230 - acc: 0.5038 - val_loss: 1.3899 - val_acc: 0.3927\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 12s 924ms/step - loss: 1.2202 - acc: 0.5042 - val_loss: 1.3885 - val_acc: 0.3927\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 12s 925ms/step - loss: 1.2175 - acc: 0.5045 - val_loss: 1.3872 - val_acc: 0.3927\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 12s 934ms/step - loss: 1.2148 - acc: 0.5051 - val_loss: 1.3858 - val_acc: 0.3964\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 12s 936ms/step - loss: 1.2121 - acc: 0.5080 - val_loss: 1.3845 - val_acc: 0.3964\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 12s 926ms/step - loss: 1.2095 - acc: 0.5096 - val_loss: 1.3831 - val_acc: 0.3964\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 12s 931ms/step - loss: 1.2068 - acc: 0.5103 - val_loss: 1.3819 - val_acc: 0.4000\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 12s 937ms/step - loss: 1.2043 - acc: 0.5109 - val_loss: 1.3806 - val_acc: 0.4000\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 12s 931ms/step - loss: 1.2017 - acc: 0.5119 - val_loss: 1.3794 - val_acc: 0.4000\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 12s 937ms/step - loss: 1.1992 - acc: 0.5160 - val_loss: 1.3783 - val_acc: 0.4000\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 12s 938ms/step - loss: 1.1967 - acc: 0.5167 - val_loss: 1.3771 - val_acc: 0.3982\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.1942 - acc: 0.5199 - val_loss: 1.3760 - val_acc: 0.3982\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 12s 923ms/step - loss: 1.1918 - acc: 0.5215 - val_loss: 1.3749 - val_acc: 0.4018\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 12s 922ms/step - loss: 1.1894 - acc: 0.5234 - val_loss: 1.3739 - val_acc: 0.4036\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 1.1870 - acc: 0.5253 - val_loss: 1.3729 - val_acc: 0.4036\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 1.1846 - acc: 0.5269 - val_loss: 1.3719 - val_acc: 0.4055\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.1822 - acc: 0.5288 - val_loss: 1.3709 - val_acc: 0.4073\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 1.1799 - acc: 0.5308 - val_loss: 1.3699 - val_acc: 0.4073\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 12s 926ms/step - loss: 1.1775 - acc: 0.5314 - val_loss: 1.3690 - val_acc: 0.4109\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 12s 921ms/step - loss: 1.1752 - acc: 0.5321 - val_loss: 1.3681 - val_acc: 0.4127\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 1.1729 - acc: 0.5330 - val_loss: 1.3672 - val_acc: 0.4109\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 12s 944ms/step - loss: 1.1707 - acc: 0.5333 - val_loss: 1.3663 - val_acc: 0.4127\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.1684 - acc: 0.5349 - val_loss: 1.3654 - val_acc: 0.4145\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 12s 933ms/step - loss: 1.1662 - acc: 0.5349 - val_loss: 1.3646 - val_acc: 0.4127\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 12s 938ms/step - loss: 1.1640 - acc: 0.5356 - val_loss: 1.3637 - val_acc: 0.4164\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 1.1617 - acc: 0.5369 - val_loss: 1.3629 - val_acc: 0.4164\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 1.1595 - acc: 0.5385 - val_loss: 1.3621 - val_acc: 0.4182\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 1.1574 - acc: 0.5391 - val_loss: 1.3613 - val_acc: 0.4182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "igkQTLIDvvsG"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OehTYDa_rd8F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "baf56dac-68f9-436c-fab8-25eb9d8c7161"
      },
      "source": [
        "loss, acc = model.evaluate(testing_ds)\n",
        "wandb.log({'Test Accuracy': round(acc*100, 2)})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 1s 320ms/step - loss: 1.3613 - acc: 0.4182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "966mDKFhqsrk"
      },
      "source": [
        "# Training Linear Classifier with Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wP6P4VcJvbDQ"
      },
      "source": [
        "#### Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hACfOEyQnk4r",
        "colab": {}
      },
      "source": [
        "# Configs\n",
        "CROP_SIZE = 224\n",
        "MIN_SCALE = 0.5\n",
        "MAX_SCALE = 1.\n",
        "\n",
        "# Experimental options\n",
        "options = tf.data.Options()\n",
        "options.experimental_optimization.noop_elimination = True\n",
        "options.experimental_optimization.map_vectorization.enabled = True\n",
        "options.experimental_optimization.apply_default_optimizations = True\n",
        "options.experimental_deterministic = False\n",
        "options.experimental_threading.max_intra_op_parallelism = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hU2OZh1oTFaN",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def scale_image(image, label):\n",
        "\timage = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\treturn (image, label)\n",
        "\n",
        "@tf.function\n",
        "def random_apply(func, x, p):\n",
        "\treturn tf.cond(\n",
        "\t\ttf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "\t\t\t\ttf.cast(p, tf.float32)),\n",
        "\t\tlambda: func(x),\n",
        "\t\tlambda: x)\n",
        " \n",
        "@tf.function\n",
        "def random_resize_crop(image, label):\n",
        "  # Conditional resizing\n",
        "  image = tf.image.resize(image, (260, 260))\n",
        "  # Get the crop size for given min and max scale\n",
        "  size = tf.random.uniform(shape=(1,), minval=MIN_SCALE*260,\n",
        "\t\t          maxval=MAX_SCALE*260, dtype=tf.float32)\n",
        "  size = tf.cast(size, tf.int32)[0]\n",
        "  # Get the crop from the image\n",
        "  crop = tf.image.random_crop(image, (size,size,3))\n",
        "  crop_resize = tf.image.resize(crop, (CROP_SIZE, CROP_SIZE))\n",
        "  \n",
        "  return crop_resize, label\n",
        "\n",
        "@tf.function\n",
        "def tie_together(image, label):\n",
        "  # Scale the pixel values\n",
        "  image, label = scale_image(image , label)\n",
        "  # random horizontal flip\n",
        "  image = random_apply(tf.image.random_flip_left_right, image, p=0.5)\n",
        "  # Random resized crops\n",
        "  image, label = random_resize_crop(image, label)\n",
        "  \n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MLzlomx_d2iO",
        "colab": {}
      },
      "source": [
        "trainloader = (\n",
        "\ttrain_ds\n",
        "\t.shuffle(1024)\n",
        "\t.map(tie_together, num_parallel_calls=AUTO)\n",
        "\t.batch(BATCH_SIZE)\n",
        "\t.prefetch(AUTO)\n",
        ")\n",
        "\n",
        "trainloader = trainloader.with_options(options)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FyG-NSONve1P"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pat13QzdtsL3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3799fdec-e055-45f1-b22c-ba89c063c95e"
      },
      "source": [
        "# get model and compile\n",
        "tf.keras.backend.clear_session()\n",
        "model = get_linear_classifier(alpha=1e-6)\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer=\"adam\")\n",
        "\n",
        "# initialize wandb run\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train \n",
        "history = model.fit(training_ds,\n",
        "                 validation_data=(testing_ds),\n",
        "                 epochs=100,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "functional_1 (Functional)    (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 10245     \n",
            "=================================================================\n",
            "Total params: 23,597,957\n",
            "Trainable params: 10,245\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/1r1vza1v\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/1r1vza1v</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 13s 1s/step - loss: 2.1446 - acc: 0.2561 - val_loss: 1.9528 - val_acc: 0.2618\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 12s 960ms/step - loss: 1.6818 - acc: 0.3006 - val_loss: 1.6579 - val_acc: 0.2600\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 12s 929ms/step - loss: 1.5806 - acc: 0.3266 - val_loss: 1.5741 - val_acc: 0.2909\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 11s 874ms/step - loss: 1.5441 - acc: 0.3282 - val_loss: 1.5746 - val_acc: 0.2855\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 12s 914ms/step - loss: 1.5295 - acc: 0.3362 - val_loss: 1.5603 - val_acc: 0.2855\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.5194 - acc: 0.3471 - val_loss: 1.5453 - val_acc: 0.2945\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 12s 934ms/step - loss: 1.5120 - acc: 0.3465 - val_loss: 1.5415 - val_acc: 0.2964\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 12s 939ms/step - loss: 1.5072 - acc: 0.3561 - val_loss: 1.5268 - val_acc: 0.3055\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 12s 937ms/step - loss: 1.4964 - acc: 0.3606 - val_loss: 1.5252 - val_acc: 0.3073\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 12s 925ms/step - loss: 1.4926 - acc: 0.3609 - val_loss: 1.5166 - val_acc: 0.3182\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 12s 920ms/step - loss: 1.4844 - acc: 0.3663 - val_loss: 1.5088 - val_acc: 0.3236\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 12s 923ms/step - loss: 1.4771 - acc: 0.3715 - val_loss: 1.5058 - val_acc: 0.3291\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 1.4676 - acc: 0.3747 - val_loss: 1.4974 - val_acc: 0.3309\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 12s 934ms/step - loss: 1.4614 - acc: 0.3776 - val_loss: 1.4953 - val_acc: 0.3327\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 12s 936ms/step - loss: 1.4521 - acc: 0.3833 - val_loss: 1.4902 - val_acc: 0.3382\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 12s 929ms/step - loss: 1.4455 - acc: 0.3856 - val_loss: 1.4863 - val_acc: 0.3418\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 12s 923ms/step - loss: 1.4387 - acc: 0.3904 - val_loss: 1.4840 - val_acc: 0.3455\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 12s 938ms/step - loss: 1.4314 - acc: 0.3933 - val_loss: 1.4802 - val_acc: 0.3455\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 12s 929ms/step - loss: 1.4251 - acc: 0.3984 - val_loss: 1.4782 - val_acc: 0.3527\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 12s 933ms/step - loss: 1.4182 - acc: 0.3994 - val_loss: 1.4760 - val_acc: 0.3473\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 12s 939ms/step - loss: 1.4117 - acc: 0.4051 - val_loss: 1.4741 - val_acc: 0.3491\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.4054 - acc: 0.4096 - val_loss: 1.4728 - val_acc: 0.3527\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 12s 922ms/step - loss: 1.3989 - acc: 0.4112 - val_loss: 1.4715 - val_acc: 0.3564\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 12s 929ms/step - loss: 1.3927 - acc: 0.4131 - val_loss: 1.4704 - val_acc: 0.3600\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 12s 941ms/step - loss: 1.3866 - acc: 0.4131 - val_loss: 1.4692 - val_acc: 0.3600\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 12s 932ms/step - loss: 1.3805 - acc: 0.4167 - val_loss: 1.4678 - val_acc: 0.3600\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 12s 924ms/step - loss: 1.3745 - acc: 0.4215 - val_loss: 1.4663 - val_acc: 0.3618\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 12s 934ms/step - loss: 1.3686 - acc: 0.4228 - val_loss: 1.4644 - val_acc: 0.3618\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 12s 936ms/step - loss: 1.3628 - acc: 0.4288 - val_loss: 1.4623 - val_acc: 0.3618\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 1.3571 - acc: 0.4317 - val_loss: 1.4600 - val_acc: 0.3636\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 12s 929ms/step - loss: 1.3516 - acc: 0.4369 - val_loss: 1.4574 - val_acc: 0.3618\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 12s 932ms/step - loss: 1.3461 - acc: 0.4385 - val_loss: 1.4548 - val_acc: 0.3636\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 1.3408 - acc: 0.4436 - val_loss: 1.4521 - val_acc: 0.3655\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 12s 935ms/step - loss: 1.3356 - acc: 0.4455 - val_loss: 1.4494 - val_acc: 0.3655\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 12s 925ms/step - loss: 1.3306 - acc: 0.4490 - val_loss: 1.4468 - val_acc: 0.3727\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 1.3256 - acc: 0.4532 - val_loss: 1.4443 - val_acc: 0.3727\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 12s 934ms/step - loss: 1.3208 - acc: 0.4561 - val_loss: 1.4418 - val_acc: 0.3727\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 12s 934ms/step - loss: 1.3162 - acc: 0.4593 - val_loss: 1.4395 - val_acc: 0.3709\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 12s 929ms/step - loss: 1.3116 - acc: 0.4622 - val_loss: 1.4373 - val_acc: 0.3709\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 1.3072 - acc: 0.4638 - val_loss: 1.4352 - val_acc: 0.3709\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 12s 936ms/step - loss: 1.3029 - acc: 0.4647 - val_loss: 1.4332 - val_acc: 0.3745\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 12s 931ms/step - loss: 1.2987 - acc: 0.4667 - val_loss: 1.4313 - val_acc: 0.3764\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 12s 924ms/step - loss: 1.2946 - acc: 0.4689 - val_loss: 1.4295 - val_acc: 0.3836\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 12s 932ms/step - loss: 1.2906 - acc: 0.4712 - val_loss: 1.4278 - val_acc: 0.3855\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 1.2866 - acc: 0.4731 - val_loss: 1.4262 - val_acc: 0.3855\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 12s 929ms/step - loss: 1.2828 - acc: 0.4744 - val_loss: 1.4246 - val_acc: 0.3855\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 12s 932ms/step - loss: 1.2790 - acc: 0.4769 - val_loss: 1.4232 - val_acc: 0.3873\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 1.2753 - acc: 0.4795 - val_loss: 1.4219 - val_acc: 0.3873\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 12s 936ms/step - loss: 1.2717 - acc: 0.4798 - val_loss: 1.4207 - val_acc: 0.3873\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 12s 931ms/step - loss: 1.2681 - acc: 0.4814 - val_loss: 1.4196 - val_acc: 0.3891\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 1.2647 - acc: 0.4843 - val_loss: 1.4185 - val_acc: 0.3873\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 12s 926ms/step - loss: 1.2613 - acc: 0.4881 - val_loss: 1.4176 - val_acc: 0.3891\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 12s 929ms/step - loss: 1.2580 - acc: 0.4897 - val_loss: 1.4168 - val_acc: 0.3964\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 12s 929ms/step - loss: 1.2547 - acc: 0.4920 - val_loss: 1.4161 - val_acc: 0.3982\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 12s 926ms/step - loss: 1.2515 - acc: 0.4942 - val_loss: 1.4155 - val_acc: 0.3964\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 12s 935ms/step - loss: 1.2484 - acc: 0.4955 - val_loss: 1.4151 - val_acc: 0.3982\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 1.2454 - acc: 0.4968 - val_loss: 1.4147 - val_acc: 0.4000\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 12s 929ms/step - loss: 1.2425 - acc: 0.4981 - val_loss: 1.4146 - val_acc: 0.3964\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 1.2397 - acc: 0.5006 - val_loss: 1.4145 - val_acc: 0.3945\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 12s 892ms/step - loss: 1.2369 - acc: 0.5022 - val_loss: 1.4147 - val_acc: 0.3945\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.2343 - acc: 0.5035Restoring model weights from the end of the best epoch.\n",
            "13/13 [==============================] - 12s 895ms/step - loss: 1.2343 - acc: 0.5035 - val_loss: 1.4150 - val_acc: 0.3945\n",
            "Epoch 00061: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eOz5DRHYv10d"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_mlWQCf-vqxn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "86d39ff1-ed23-4b20-db47-5728ab56792b"
      },
      "source": [
        "loss, acc = model.evaluate(testing_ds)\n",
        "wandb.log({'Test Accuracy': round(acc*100, 2)})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 1s 325ms/step - loss: 1.4145 - acc: 0.3945\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}