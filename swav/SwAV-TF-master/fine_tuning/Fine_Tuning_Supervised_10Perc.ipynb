{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BhtA_QHMgNMw"
   },
   "source": [
    "# Imports and Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1c99jQL0KMr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "tf.random.set_seed(666)\n",
    "np.random.seed(666)\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ajrzwUMZgRRi"
   },
   "source": [
    "### W&B - Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTsiFHLcgVpO"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "V53zG0-vgYdO",
    "outputId": "f3afa664-7aea-42d4-c830-6d5a6b5f98ee"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnhWEo8_12FK"
   },
   "source": [
    "## Dataset gathering and preparation\n",
    "\n",
    "Only **10%** labeled data is being used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "BAOhOFMs110h",
    "outputId": "e4c2cfb2-ef2c-4feb-972e-08dfb3ad857b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Dataset tf_flowers is hosted on GCS. It will automatically be downloaded to your\n",
      "local data directory. If you'd instead prefer to read directly from our public\n",
      "GCS bucket (recommended if you're running on GCP), you can instead set\n",
      "data_dir=gs://tfds-data/datasets.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset tf_flowers/3.0.0 (download: 218.21 MiB, generated: Unknown size, total: 218.21 MiB) to /root/tensorflow_datasets/tf_flowers/3.0.0...\u001b[0m\n",
      "\u001b[1mDataset tf_flowers downloaded and prepared to /root/tensorflow_datasets/tf_flowers/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Gather Flowers dataset\n",
    "train_ds, extra_train_ds, validation_ds = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:10%]\", \"train[10%:85%]\", \"train[85%:]\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "@tf.function\n",
    "def scale_resize_image(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, (224, 224)) # Resizing to highest resolution used while training swav\n",
    "    return (image, label)\n",
    "\n",
    "training_ds = (\n",
    "    train_ds\n",
    "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "testing_ds = (\n",
    "    validation_ds\n",
    "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqOBLHJa5Ztp"
   },
   "source": [
    "## ResNet50 base and a custom classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Znqofzfr46-4"
   },
   "outputs": [],
   "source": [
    "def get_training_model(trainable=False):\n",
    "    inputs = layers.Input(shape=(224, 224, 3))\n",
    "    EXTRACTOR = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False,\n",
    "        input_shape=(224, 224, 3))\n",
    "    EXTRACTOR.trainable = trainable\n",
    "    x = EXTRACTOR(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(5, activation=\"softmax\")(x)\n",
    "    classifier = models.Model(inputs=inputs, outputs=x)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "qtt4jmzzxe8Y",
    "outputId": "af8e19c3-a152-4db4-ccf9-788b90d54bff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 1s 0us/step\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 10245     \n",
      "=================================================================\n",
      "Total params: 23,597,957\n",
      "Trainable params: 10,245\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_training_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I0o5LHV0pCPu"
   },
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vECu62eyCdut"
   },
   "outputs": [],
   "source": [
    "# Early Stopping to prevent overfitting\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, verbose=2, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rp1fJIEYpFIC"
   },
   "source": [
    "## Without Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEY1h0L2XjBJ"
   },
   "source": [
    "### Warm Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "colab_type": "code",
    "id": "RArUvFToDJKn",
    "outputId": "c639a782-60b6-425c-c659-70b88b71e6db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/35dokky0\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/35dokky0</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "6/6 [==============================] - 3s 513ms/step - loss: 1.8391 - acc: 0.2044 - val_loss: 1.6250 - val_acc: 0.2055\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 2s 320ms/step - loss: 1.6024 - acc: 0.2888 - val_loss: 1.7046 - val_acc: 0.2145\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.6264 - acc: 0.3079Restoring model weights from the end of the best epoch.\n",
      "6/6 [==============================] - 2s 359ms/step - loss: 1.6264 - acc: 0.3079 - val_loss: 1.6490 - val_acc: 0.2436\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "# get model and compile\n",
    "tf.keras.backend.clear_session()\n",
    "model = get_training_model()\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
    "                     optimizer='adam')\n",
    "\n",
    "# initialize wandb run\n",
    "wandb.init(entity='authors', project='swav-tf')\n",
    "\n",
    "# train\n",
    "history = model.fit(training_ds,\n",
    "                 validation_data=testing_ds,\n",
    "                 epochs=35,\n",
    "                 callbacks=[WandbCallback(),\n",
    "                            early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fk_M5nFZeEOr"
   },
   "outputs": [],
   "source": [
    "model.save('warmup.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UIgLm-WzahA8"
   },
   "source": [
    "### Fine tune CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "colab_type": "code",
    "id": "6EHIchqPm_qj",
    "outputId": "e025ce51-906e-4eb0-bf39-72ab218587d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/2s15oid1\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/2s15oid1</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "6/6 [==============================] - 6s 924ms/step - loss: 1.5775 - acc: 0.3025 - val_loss: 1.5856 - val_acc: 0.2527\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 3s 507ms/step - loss: 1.5114 - acc: 0.3542 - val_loss: 1.6024 - val_acc: 0.2491\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4678 - acc: 0.3651Restoring model weights from the end of the best epoch.\n",
      "6/6 [==============================] - 3s 519ms/step - loss: 1.4678 - acc: 0.3651 - val_loss: 1.6279 - val_acc: 0.2527\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "# prepare model and compile\n",
    "model.layers[1].trainable = True\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
    "                     optimizer=tf.keras.optimizers.Adam(1e-5))\n",
    "\n",
    "# initialize wandb run\n",
    "wandb.init(entity='authors', project='swav-tf')\n",
    "\n",
    "# train\n",
    "history = model.fit(training_ds,\n",
    "                 validation_data=testing_ds,\n",
    "                 epochs=35,\n",
    "                 callbacks=[WandbCallback(),\n",
    "                            early_stopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_A1MEseWih3a"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "bmXHuzBGijmH",
    "outputId": "5ac1eda6-6942-4fbe-84f4-209c8b5eae3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 107ms/step - loss: 1.5856 - acc: 0.2527\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(testing_ds)\n",
    "wandb.log({'Test Accuracy': round(acc*100, 2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "966mDKFhqsrk"
   },
   "source": [
    "# Training with Augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPlQ3JKtq6j-"
   },
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hACfOEyQnk4r"
   },
   "outputs": [],
   "source": [
    "# Configs\n",
    "CROP_SIZE = 224\n",
    "MIN_SCALE = 0.5\n",
    "MAX_SCALE = 1.\n",
    "\n",
    "# Experimental options\n",
    "options = tf.data.Options()\n",
    "options.experimental_optimization.noop_elimination = True\n",
    "options.experimental_optimization.map_vectorization.enabled = True\n",
    "options.experimental_optimization.apply_default_optimizations = True\n",
    "options.experimental_deterministic = False\n",
    "options.experimental_threading.max_intra_op_parallelism = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hU2OZh1oTFaN"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def scale_image(image, label):\n",
    "\timage = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\treturn (image, label)\n",
    "\n",
    "@tf.function\n",
    "def random_apply(func, x, p):\n",
    "\treturn tf.cond(\n",
    "\t\ttf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
    "\t\t\t\ttf.cast(p, tf.float32)),\n",
    "\t\tlambda: func(x),\n",
    "\t\tlambda: x)\n",
    " \n",
    "@tf.function\n",
    "def random_resize_crop(image, label):\n",
    "  # Conditional resizing\n",
    "  image = tf.image.resize(image, (260, 260))\n",
    "  # Get the crop size for given min and max scale\n",
    "  size = tf.random.uniform(shape=(1,), minval=MIN_SCALE*260,\n",
    "\t\t          maxval=MAX_SCALE*260, dtype=tf.float32)\n",
    "  size = tf.cast(size, tf.int32)[0]\n",
    "  # Get the crop from the image\n",
    "  crop = tf.image.random_crop(image, (size,size,3))\n",
    "  crop_resize = tf.image.resize(crop, (CROP_SIZE, CROP_SIZE))\n",
    "  \n",
    "  return crop_resize, label\n",
    "\n",
    "@tf.function\n",
    "def tie_together(image, label):\n",
    "  # Scale the pixel values\n",
    "  image, label = scale_image(image , label)\n",
    "  # random horizontal flip\n",
    "  image = random_apply(tf.image.random_flip_left_right, image, p=0.5)\n",
    "  # Random resized crops\n",
    "  image, label = random_resize_crop(image, label)\n",
    "  \n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MLzlomx_d2iO"
   },
   "outputs": [],
   "source": [
    "trainloader = (\n",
    "\ttrain_ds\n",
    "\t.shuffle(1024)\n",
    "\t.map(tie_together, num_parallel_calls=AUTO)\n",
    "\t.batch(BATCH_SIZE)\n",
    "\t.prefetch(AUTO)\n",
    ")\n",
    "\n",
    "trainloader = trainloader.with_options(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PBzTIQAqtsLu"
   },
   "source": [
    "### Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 688
    },
    "colab_type": "code",
    "id": "Pat13QzdtsL3",
    "outputId": "7dc44acf-77f3-47ed-e35c-400a95ccce5a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/35sb2ql5\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/35sb2ql5</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "6/6 [==============================] - 3s 509ms/step - loss: 1.8788 - acc: 0.2916 - val_loss: 1.6496 - val_acc: 0.2055\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 2s 400ms/step - loss: 1.6126 - acc: 0.2343 - val_loss: 1.6411 - val_acc: 0.2291\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 3s 452ms/step - loss: 1.6228 - acc: 0.2561 - val_loss: 1.6226 - val_acc: 0.2145\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 3s 476ms/step - loss: 1.5738 - acc: 0.2970 - val_loss: 1.6112 - val_acc: 0.2200\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 3s 450ms/step - loss: 1.5685 - acc: 0.3106 - val_loss: 1.5797 - val_acc: 0.2764\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 3s 463ms/step - loss: 1.5490 - acc: 0.3433 - val_loss: 1.5661 - val_acc: 0.2745\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 3s 459ms/step - loss: 1.5447 - acc: 0.3134 - val_loss: 1.5596 - val_acc: 0.2582\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 2s 410ms/step - loss: 1.5371 - acc: 0.3324 - val_loss: 1.5488 - val_acc: 0.2873\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 2s 369ms/step - loss: 1.5249 - acc: 0.3188 - val_loss: 1.5543 - val_acc: 0.2909\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 2s 400ms/step - loss: 1.5322 - acc: 0.3433 - val_loss: 1.5324 - val_acc: 0.3145\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 3s 460ms/step - loss: 1.5231 - acc: 0.3569 - val_loss: 1.5320 - val_acc: 0.2982\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 3s 462ms/step - loss: 1.5125 - acc: 0.3406 - val_loss: 1.5309 - val_acc: 0.2945\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 3s 447ms/step - loss: 1.5105 - acc: 0.3787 - val_loss: 1.5176 - val_acc: 0.3582\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 2s 372ms/step - loss: 1.5085 - acc: 0.3733 - val_loss: 1.5305 - val_acc: 0.2964\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.5103 - acc: 0.3406Restoring model weights from the end of the best epoch.\n",
      "6/6 [==============================] - 2s 334ms/step - loss: 1.5103 - acc: 0.3406 - val_loss: 1.5209 - val_acc: 0.3109\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "# get model and compile\n",
    "tf.keras.backend.clear_session()\n",
    "model = get_training_model()\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
    "                     optimizer='adam')\n",
    "\n",
    "# initialize wandb run\n",
    "wandb.init(entity='authors', project='swav-tf')\n",
    "\n",
    "# train\n",
    "history = model.fit(trainloader,\n",
    "                 validation_data=testing_ds,\n",
    "                 epochs=35,\n",
    "                 callbacks=[WandbCallback(),\n",
    "                            early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hD-oqM7wslOr"
   },
   "outputs": [],
   "source": [
    "model.save('warmup_augmentation.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q0IBzaXysj60"
   },
   "source": [
    "### Fine tune CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "colab_type": "code",
    "id": "3BoSzbemsj7F",
    "outputId": "f3399094-27d6-4df7-960f-5ae0cb24d593"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/ailwhscb\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/ailwhscb</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "6/6 [==============================] - 5s 835ms/step - loss: 1.5755 - acc: 0.3488 - val_loss: 1.5523 - val_acc: 0.2655\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 4s 716ms/step - loss: 1.5667 - acc: 0.3025 - val_loss: 1.5421 - val_acc: 0.3273\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 4s 714ms/step - loss: 1.5191 - acc: 0.3433 - val_loss: 1.5387 - val_acc: 0.2927\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 4s 735ms/step - loss: 1.4997 - acc: 0.3460 - val_loss: 1.5335 - val_acc: 0.3309\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 3s 494ms/step - loss: 1.5293 - acc: 0.3515 - val_loss: 1.5361 - val_acc: 0.3400\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 4s 697ms/step - loss: 1.5210 - acc: 0.3515 - val_loss: 1.5091 - val_acc: 0.3145\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 3s 527ms/step - loss: 1.4800 - acc: 0.3978 - val_loss: 1.5227 - val_acc: 0.3036\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4849 - acc: 0.3569Restoring model weights from the end of the best epoch.\n",
      "6/6 [==============================] - 3s 517ms/step - loss: 1.4849 - acc: 0.3569 - val_loss: 1.5192 - val_acc: 0.3345\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "# prepare model and compile\n",
    "model.layers[1].trainable = True\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
    "                     optimizer=tf.keras.optimizers.Adam(1e-5))\n",
    "\n",
    "# initialize wandb run\n",
    "wandb.init(entity='authors', project='swav-tf')\n",
    "\n",
    "# train\n",
    "history = model.fit(trainloader,\n",
    "                 validation_data=testing_ds,\n",
    "                 epochs=35,\n",
    "                 callbacks=[WandbCallback(),\n",
    "                            early_stopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "prZcXHyskW4f"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "mztmMjICkW4r",
    "outputId": "81a96173-ab0f-491b-fc58-5e2f54ca6f9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 108ms/step - loss: 1.5091 - acc: 0.3145\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(testing_ds)\n",
    "wandb.log({'Test Accuracy': round(acc*100, 2)})"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Fine_Tuning_on_Flower_Dataset_Supervised.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
