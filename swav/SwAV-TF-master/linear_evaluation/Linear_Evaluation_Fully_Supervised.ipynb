{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZlN8EEM6NVC"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1c99jQL0KMr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "tf.random.set_seed(666)\n",
    "np.random.seed(666)\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "ATfRWo0x6Vkp",
    "outputId": "6cbdcc82-7e5e-4441-d7ad-7e119f513ec2"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnhWEo8_12FK"
   },
   "source": [
    "## Dataset gathering and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "BAOhOFMs110h",
    "outputId": "1c68bc8d-407d-4983-d4ec-fe0ff2e855ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Dataset tf_flowers is hosted on GCS. It will automatically be downloaded to your\n",
      "local data directory. If you'd instead prefer to read directly from our public\n",
      "GCS bucket (recommended if you're running on GCP), you can instead set\n",
      "data_dir=gs://tfds-data/datasets.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset tf_flowers/3.0.0 (download: 218.21 MiB, generated: Unknown size, total: 218.21 MiB) to /root/tensorflow_datasets/tf_flowers/3.0.0...\u001b[0m\n",
      "\u001b[1mDataset tf_flowers downloaded and prepared to /root/tensorflow_datasets/tf_flowers/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Gather Flowers dataset\n",
    "train_ds, validation_ds = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:85%]\", \"train[85%:]\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "@tf.function\n",
    "def scale_resize_image(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, (224, 224)) # Resizing to highest resolution used while training swav\n",
    "    return (image, label)\n",
    "\n",
    "training_ds = (\n",
    "    train_ds\n",
    "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "testing_ds = (\n",
    "    validation_ds\n",
    "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqOBLHJa5Ztp"
   },
   "source": [
    "## ResNet50 base and a custom classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Znqofzfr46-4"
   },
   "outputs": [],
   "source": [
    "def get_training_model(trainable=False):\n",
    "    inputs = layers.Input(shape=(224, 224, 3))\n",
    "    EXTRACTOR = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False,\n",
    "        input_shape=(224, 224, 3))\n",
    "    EXTRACTOR.trainable = trainable\n",
    "    x = EXTRACTOR(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(5, activation=\"softmax\")(x)\n",
    "    classifier = models.Model(inputs=inputs, outputs=x)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "qtt4jmzzxe8Y",
    "outputId": "2e225ce5-5cff-4132-f5a1-73ccf5d73b8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 1s 0us/step\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 10245     \n",
      "=================================================================\n",
      "Total params: 23,597,957\n",
      "Trainable params: 10,245\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_training_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I0o5LHV0pCPu"
   },
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vECu62eyCdut"
   },
   "outputs": [],
   "source": [
    "# Early Stopping to prevent overfitting\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, verbose=2, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rp1fJIEYpFIC"
   },
   "source": [
    "## Without Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HdC-897fDXxC"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RArUvFToDJKn",
    "outputId": "8a6395d3-9995-4906-a927-ab9078e277fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 10245     \n",
      "=================================================================\n",
      "Total params: 23,597,957\n",
      "Trainable params: 10,245\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/2zi6qq6s\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/2zi6qq6s</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 23s 2s/step - loss: 1.6661 - acc: 0.1978 - val_loss: 1.6145 - val_acc: 0.2600\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.5835 - acc: 0.2705 - val_loss: 1.5711 - val_acc: 0.3018\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.5418 - acc: 0.3487 - val_loss: 1.5442 - val_acc: 0.2873\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.5127 - acc: 0.3561 - val_loss: 1.5242 - val_acc: 0.3327\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4962 - acc: 0.3728 - val_loss: 1.5115 - val_acc: 0.3400\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.4815 - acc: 0.3817 - val_loss: 1.5017 - val_acc: 0.3436\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.4712 - acc: 0.3859 - val_loss: 1.4934 - val_acc: 0.3455\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4628 - acc: 0.3904 - val_loss: 1.4861 - val_acc: 0.3527\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.4552 - acc: 0.3913 - val_loss: 1.4798 - val_acc: 0.3618\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.4488 - acc: 0.3936 - val_loss: 1.4739 - val_acc: 0.3655\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4429 - acc: 0.3994 - val_loss: 1.4683 - val_acc: 0.3618\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4374 - acc: 0.4042 - val_loss: 1.4631 - val_acc: 0.3745\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4323 - acc: 0.4074 - val_loss: 1.4581 - val_acc: 0.3782\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.4276 - acc: 0.4087 - val_loss: 1.4534 - val_acc: 0.3855\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.4230 - acc: 0.4115 - val_loss: 1.4488 - val_acc: 0.3927\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4187 - acc: 0.4147 - val_loss: 1.4443 - val_acc: 0.4000\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.4146 - acc: 0.4173 - val_loss: 1.4400 - val_acc: 0.4036\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4106 - acc: 0.4199 - val_loss: 1.4358 - val_acc: 0.4091\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4067 - acc: 0.4237 - val_loss: 1.4318 - val_acc: 0.4109\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4030 - acc: 0.4240 - val_loss: 1.4278 - val_acc: 0.4127\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3994 - acc: 0.4266 - val_loss: 1.4240 - val_acc: 0.4145\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3959 - acc: 0.4295 - val_loss: 1.4203 - val_acc: 0.4145\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3925 - acc: 0.4311 - val_loss: 1.4166 - val_acc: 0.4164\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3892 - acc: 0.4317 - val_loss: 1.4131 - val_acc: 0.4218\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3860 - acc: 0.4333 - val_loss: 1.4096 - val_acc: 0.4236\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3828 - acc: 0.4353 - val_loss: 1.4062 - val_acc: 0.4273\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3798 - acc: 0.4356 - val_loss: 1.4029 - val_acc: 0.4309\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3768 - acc: 0.4388 - val_loss: 1.3996 - val_acc: 0.4291\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3739 - acc: 0.4404 - val_loss: 1.3965 - val_acc: 0.4364\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3710 - acc: 0.4407 - val_loss: 1.3934 - val_acc: 0.4400\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3682 - acc: 0.4429 - val_loss: 1.3904 - val_acc: 0.4418\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3654 - acc: 0.4446 - val_loss: 1.3874 - val_acc: 0.4418\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3627 - acc: 0.4465 - val_loss: 1.3845 - val_acc: 0.4400\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3601 - acc: 0.4494 - val_loss: 1.3817 - val_acc: 0.4418\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3575 - acc: 0.4538 - val_loss: 1.3789 - val_acc: 0.4400\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3550 - acc: 0.4548 - val_loss: 1.3762 - val_acc: 0.4418\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3525 - acc: 0.4577 - val_loss: 1.3735 - val_acc: 0.4455\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3501 - acc: 0.4609 - val_loss: 1.3709 - val_acc: 0.4491\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3477 - acc: 0.4622 - val_loss: 1.3683 - val_acc: 0.4509\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3453 - acc: 0.4622 - val_loss: 1.3658 - val_acc: 0.4545\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3430 - acc: 0.4641 - val_loss: 1.3634 - val_acc: 0.4545\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3407 - acc: 0.4660 - val_loss: 1.3609 - val_acc: 0.4545\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3385 - acc: 0.4673 - val_loss: 1.3586 - val_acc: 0.4527\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3363 - acc: 0.4686 - val_loss: 1.3562 - val_acc: 0.4491\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3341 - acc: 0.4696 - val_loss: 1.3539 - val_acc: 0.4527\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3320 - acc: 0.4708 - val_loss: 1.3517 - val_acc: 0.4491\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3299 - acc: 0.4718 - val_loss: 1.3495 - val_acc: 0.4509\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3278 - acc: 0.4737 - val_loss: 1.3473 - val_acc: 0.4527\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3258 - acc: 0.4769 - val_loss: 1.3451 - val_acc: 0.4527\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3237 - acc: 0.4785 - val_loss: 1.3430 - val_acc: 0.4545\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3218 - acc: 0.4795 - val_loss: 1.3410 - val_acc: 0.4545\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3198 - acc: 0.4817 - val_loss: 1.3389 - val_acc: 0.4545\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3179 - acc: 0.4827 - val_loss: 1.3369 - val_acc: 0.4527\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3160 - acc: 0.4833 - val_loss: 1.3350 - val_acc: 0.4545\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3141 - acc: 0.4843 - val_loss: 1.3330 - val_acc: 0.4564\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3123 - acc: 0.4853 - val_loss: 1.3311 - val_acc: 0.4600\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3104 - acc: 0.4865 - val_loss: 1.3292 - val_acc: 0.4618\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3086 - acc: 0.4888 - val_loss: 1.3274 - val_acc: 0.4636\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3069 - acc: 0.4894 - val_loss: 1.3256 - val_acc: 0.4655\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3051 - acc: 0.4894 - val_loss: 1.3238 - val_acc: 0.4673\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3034 - acc: 0.4917 - val_loss: 1.3220 - val_acc: 0.4673\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3017 - acc: 0.4913 - val_loss: 1.3202 - val_acc: 0.4673\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3000 - acc: 0.4917 - val_loss: 1.3185 - val_acc: 0.4655\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2983 - acc: 0.4923 - val_loss: 1.3168 - val_acc: 0.4636\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2966 - acc: 0.4936 - val_loss: 1.3151 - val_acc: 0.4636\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2950 - acc: 0.4936 - val_loss: 1.3135 - val_acc: 0.4655\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2934 - acc: 0.4946 - val_loss: 1.3119 - val_acc: 0.4636\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2918 - acc: 0.4952 - val_loss: 1.3103 - val_acc: 0.4655\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2902 - acc: 0.4965 - val_loss: 1.3087 - val_acc: 0.4655\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2887 - acc: 0.4965 - val_loss: 1.3071 - val_acc: 0.4655\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2871 - acc: 0.4978 - val_loss: 1.3056 - val_acc: 0.4655\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2856 - acc: 0.4987 - val_loss: 1.3041 - val_acc: 0.4673\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2841 - acc: 0.4990 - val_loss: 1.3026 - val_acc: 0.4673\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2826 - acc: 0.4997 - val_loss: 1.3011 - val_acc: 0.4673\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2811 - acc: 0.5006 - val_loss: 1.2996 - val_acc: 0.4691\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2796 - acc: 0.5000 - val_loss: 1.2982 - val_acc: 0.4709\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2782 - acc: 0.5019 - val_loss: 1.2967 - val_acc: 0.4727\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2767 - acc: 0.5032 - val_loss: 1.2953 - val_acc: 0.4727\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2753 - acc: 0.5061 - val_loss: 1.2939 - val_acc: 0.4709\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2739 - acc: 0.5067 - val_loss: 1.2926 - val_acc: 0.4709\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2725 - acc: 0.5077 - val_loss: 1.2912 - val_acc: 0.4709\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2711 - acc: 0.5080 - val_loss: 1.2898 - val_acc: 0.4727\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2697 - acc: 0.5087 - val_loss: 1.2885 - val_acc: 0.4764\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2684 - acc: 0.5090 - val_loss: 1.2872 - val_acc: 0.4764\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2670 - acc: 0.5093 - val_loss: 1.2859 - val_acc: 0.4764\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2657 - acc: 0.5103 - val_loss: 1.2846 - val_acc: 0.4764\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2644 - acc: 0.5106 - val_loss: 1.2834 - val_acc: 0.4782\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2631 - acc: 0.5115 - val_loss: 1.2821 - val_acc: 0.4782\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2618 - acc: 0.5122 - val_loss: 1.2809 - val_acc: 0.4782\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2605 - acc: 0.5125 - val_loss: 1.2796 - val_acc: 0.4800\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2592 - acc: 0.5128 - val_loss: 1.2784 - val_acc: 0.4800\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2580 - acc: 0.5147 - val_loss: 1.2772 - val_acc: 0.4818\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2567 - acc: 0.5160 - val_loss: 1.2760 - val_acc: 0.4836\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2555 - acc: 0.5173 - val_loss: 1.2749 - val_acc: 0.4836\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2542 - acc: 0.5176 - val_loss: 1.2737 - val_acc: 0.4836\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2530 - acc: 0.5176 - val_loss: 1.2726 - val_acc: 0.4855\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2518 - acc: 0.5183 - val_loss: 1.2714 - val_acc: 0.4855\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2506 - acc: 0.5189 - val_loss: 1.2703 - val_acc: 0.4836\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2494 - acc: 0.5189 - val_loss: 1.2692 - val_acc: 0.4836\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2482 - acc: 0.5192 - val_loss: 1.2681 - val_acc: 0.4836\n"
     ]
    }
   ],
   "source": [
    "# get model and compile\n",
    "tf.keras.backend.clear_session()\n",
    "model = get_training_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
    "                     optimizer=\"adam\")\n",
    "\n",
    "# initialize wandb run\n",
    "wandb.init(entity='authors', project='swav-tf')\n",
    "\n",
    "# train \n",
    "history = model.fit(training_ds,\n",
    "                 validation_data=(testing_ds),\n",
    "                 epochs=100,\n",
    "                 callbacks=[WandbCallback(),\n",
    "                            early_stopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMUITZxpDaS8"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "KNpchslXDPFR",
    "outputId": "9c9785ad-d4d1-41c0-f3af-8953cb02fef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 570ms/step - loss: 1.2681 - acc: 0.4836\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(testing_ds)\n",
    "wandb.log({'Test Accuracy': round(acc*100, 2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "966mDKFhqsrk"
   },
   "source": [
    "# Training with Augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPlQ3JKtq6j-"
   },
   "source": [
    "#### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hACfOEyQnk4r"
   },
   "outputs": [],
   "source": [
    "# Configs\n",
    "CROP_SIZE = 224\n",
    "MIN_SCALE = 0.5\n",
    "MAX_SCALE = 1.\n",
    "\n",
    "# Experimental options\n",
    "options = tf.data.Options()\n",
    "options.experimental_optimization.noop_elimination = True\n",
    "options.experimental_optimization.map_vectorization.enabled = True\n",
    "options.experimental_optimization.apply_default_optimizations = True\n",
    "options.experimental_deterministic = False\n",
    "options.experimental_threading.max_intra_op_parallelism = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hU2OZh1oTFaN"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def scale_image(image, label):\n",
    "\timage = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\treturn (image, label)\n",
    "\n",
    "@tf.function\n",
    "def random_apply(func, x, p):\n",
    "\treturn tf.cond(\n",
    "\t\ttf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
    "\t\t\t\ttf.cast(p, tf.float32)),\n",
    "\t\tlambda: func(x),\n",
    "\t\tlambda: x)\n",
    " \n",
    "@tf.function\n",
    "def random_resize_crop(image, label):\n",
    "  # Conditional resizing\n",
    "  image = tf.image.resize(image, (260, 260))\n",
    "  # Get the crop size for given min and max scale\n",
    "  size = tf.random.uniform(shape=(1,), minval=MIN_SCALE*260,\n",
    "\t\t          maxval=MAX_SCALE*260, dtype=tf.float32)\n",
    "  size = tf.cast(size, tf.int32)[0]\n",
    "  # Get the crop from the image\n",
    "  crop = tf.image.random_crop(image, (size,size,3))\n",
    "  crop_resize = tf.image.resize(crop, (CROP_SIZE, CROP_SIZE))\n",
    "  \n",
    "  return crop_resize, label\n",
    "\n",
    "@tf.function\n",
    "def tie_together(image, label):\n",
    "  # Scale the pixel values\n",
    "  image, label = scale_image(image , label)\n",
    "  # random horizontal flip\n",
    "  image = random_apply(tf.image.random_flip_left_right, image, p=0.5)\n",
    "  # Random resized crops\n",
    "  image, label = random_resize_crop(image, label)\n",
    "  \n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MLzlomx_d2iO"
   },
   "outputs": [],
   "source": [
    "trainloader = (\n",
    "\ttrain_ds\n",
    "\t.shuffle(1024)\n",
    "\t.map(tie_together, num_parallel_calls=AUTO)\n",
    "\t.batch(BATCH_SIZE)\n",
    "\t.prefetch(AUTO)\n",
    ")\n",
    "\n",
    "trainloader = trainloader.with_options(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3CxMB95EVo9"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Pat13QzdtsL3",
    "outputId": "a077d22f-04df-4998-c1af-e1311637a379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 10245     \n",
      "=================================================================\n",
      "Total params: 23,597,957\n",
      "Trainable params: 10,245\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/1ubbg4e2\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/1ubbg4e2</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.6408 - acc: 0.2147 - val_loss: 1.6153 - val_acc: 0.2509\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.5725 - acc: 0.3135 - val_loss: 1.5623 - val_acc: 0.2836\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.5340 - acc: 0.3333 - val_loss: 1.5386 - val_acc: 0.3127\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.5101 - acc: 0.3641 - val_loss: 1.5243 - val_acc: 0.3164\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4937 - acc: 0.3724 - val_loss: 1.5114 - val_acc: 0.3291\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4813 - acc: 0.3747 - val_loss: 1.5022 - val_acc: 0.3455\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4717 - acc: 0.3801 - val_loss: 1.4940 - val_acc: 0.3582\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.4632 - acc: 0.3853 - val_loss: 1.4868 - val_acc: 0.3727\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.4558 - acc: 0.3907 - val_loss: 1.4804 - val_acc: 0.3800\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.4493 - acc: 0.3962 - val_loss: 1.4744 - val_acc: 0.3800\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4432 - acc: 0.4019 - val_loss: 1.4688 - val_acc: 0.3836\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4377 - acc: 0.4058 - val_loss: 1.4635 - val_acc: 0.3855\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.4324 - acc: 0.4054 - val_loss: 1.4585 - val_acc: 0.3818\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.4275 - acc: 0.4074 - val_loss: 1.4536 - val_acc: 0.3818\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4229 - acc: 0.4109 - val_loss: 1.4490 - val_acc: 0.3855\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.4184 - acc: 0.4138 - val_loss: 1.4445 - val_acc: 0.3873\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.4142 - acc: 0.4154 - val_loss: 1.4402 - val_acc: 0.3873\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4101 - acc: 0.4186 - val_loss: 1.4360 - val_acc: 0.3945\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4062 - acc: 0.4215 - val_loss: 1.4319 - val_acc: 0.3982\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.4024 - acc: 0.4221 - val_loss: 1.4279 - val_acc: 0.4036\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3987 - acc: 0.4263 - val_loss: 1.4241 - val_acc: 0.4091\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3951 - acc: 0.4298 - val_loss: 1.4203 - val_acc: 0.4091\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3916 - acc: 0.4301 - val_loss: 1.4167 - val_acc: 0.4055\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3883 - acc: 0.4333 - val_loss: 1.4131 - val_acc: 0.4109\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3850 - acc: 0.4353 - val_loss: 1.4096 - val_acc: 0.4109\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3818 - acc: 0.4369 - val_loss: 1.4063 - val_acc: 0.4145\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3787 - acc: 0.4391 - val_loss: 1.4030 - val_acc: 0.4236\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3757 - acc: 0.4404 - val_loss: 1.3997 - val_acc: 0.4236\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3727 - acc: 0.4423 - val_loss: 1.3966 - val_acc: 0.4273\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3698 - acc: 0.4465 - val_loss: 1.3935 - val_acc: 0.4273\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3670 - acc: 0.4471 - val_loss: 1.3905 - val_acc: 0.4291\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3642 - acc: 0.4484 - val_loss: 1.3875 - val_acc: 0.4364\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3615 - acc: 0.4497 - val_loss: 1.3846 - val_acc: 0.4364\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3588 - acc: 0.4519 - val_loss: 1.3818 - val_acc: 0.4418\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3562 - acc: 0.4538 - val_loss: 1.3790 - val_acc: 0.4436\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3537 - acc: 0.4558 - val_loss: 1.3763 - val_acc: 0.4455\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3512 - acc: 0.4583 - val_loss: 1.3737 - val_acc: 0.4473\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3487 - acc: 0.4603 - val_loss: 1.3711 - val_acc: 0.4455\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3463 - acc: 0.4615 - val_loss: 1.3685 - val_acc: 0.4455\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3439 - acc: 0.4635 - val_loss: 1.3660 - val_acc: 0.4455\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3416 - acc: 0.4651 - val_loss: 1.3636 - val_acc: 0.4455\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3393 - acc: 0.4667 - val_loss: 1.3611 - val_acc: 0.4473\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3371 - acc: 0.4686 - val_loss: 1.3588 - val_acc: 0.4491\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3349 - acc: 0.4689 - val_loss: 1.3565 - val_acc: 0.4491\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3327 - acc: 0.4702 - val_loss: 1.3542 - val_acc: 0.4509\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3305 - acc: 0.4712 - val_loss: 1.3519 - val_acc: 0.4545\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3284 - acc: 0.4731 - val_loss: 1.3497 - val_acc: 0.4527\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3264 - acc: 0.4753 - val_loss: 1.3476 - val_acc: 0.4509\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3243 - acc: 0.4782 - val_loss: 1.3454 - val_acc: 0.4545\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3223 - acc: 0.4788 - val_loss: 1.3434 - val_acc: 0.4582\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3203 - acc: 0.4798 - val_loss: 1.3413 - val_acc: 0.4582\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3184 - acc: 0.4814 - val_loss: 1.3393 - val_acc: 0.4582\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3165 - acc: 0.4824 - val_loss: 1.3373 - val_acc: 0.4582\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3146 - acc: 0.4840 - val_loss: 1.3353 - val_acc: 0.4600\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3127 - acc: 0.4849 - val_loss: 1.3334 - val_acc: 0.4600\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3108 - acc: 0.4846 - val_loss: 1.3315 - val_acc: 0.4600\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3090 - acc: 0.4875 - val_loss: 1.3296 - val_acc: 0.4582\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3072 - acc: 0.4888 - val_loss: 1.3278 - val_acc: 0.4636\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3054 - acc: 0.4894 - val_loss: 1.3260 - val_acc: 0.4618\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.3037 - acc: 0.4891 - val_loss: 1.3242 - val_acc: 0.4618\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3020 - acc: 0.4897 - val_loss: 1.3224 - val_acc: 0.4618\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.3002 - acc: 0.4904 - val_loss: 1.3207 - val_acc: 0.4618\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2986 - acc: 0.4913 - val_loss: 1.3190 - val_acc: 0.4655\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2969 - acc: 0.4923 - val_loss: 1.3173 - val_acc: 0.4673\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2952 - acc: 0.4929 - val_loss: 1.3156 - val_acc: 0.4673\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2936 - acc: 0.4936 - val_loss: 1.3140 - val_acc: 0.4655\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2920 - acc: 0.4958 - val_loss: 1.3124 - val_acc: 0.4691\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2904 - acc: 0.4971 - val_loss: 1.3108 - val_acc: 0.4691\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2888 - acc: 0.4981 - val_loss: 1.3092 - val_acc: 0.4691\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2873 - acc: 0.4990 - val_loss: 1.3077 - val_acc: 0.4691\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2857 - acc: 0.4990 - val_loss: 1.3061 - val_acc: 0.4727\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2842 - acc: 0.4997 - val_loss: 1.3046 - val_acc: 0.4709\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2827 - acc: 0.5006 - val_loss: 1.3031 - val_acc: 0.4709\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2812 - acc: 0.5019 - val_loss: 1.3017 - val_acc: 0.4727\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2797 - acc: 0.5026 - val_loss: 1.3002 - val_acc: 0.4745\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2783 - acc: 0.5035 - val_loss: 1.2988 - val_acc: 0.4745\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2768 - acc: 0.5048 - val_loss: 1.2974 - val_acc: 0.4764\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2754 - acc: 0.5048 - val_loss: 1.2960 - val_acc: 0.4782\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2740 - acc: 0.5051 - val_loss: 1.2946 - val_acc: 0.4764\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2726 - acc: 0.5067 - val_loss: 1.2932 - val_acc: 0.4764\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2712 - acc: 0.5077 - val_loss: 1.2918 - val_acc: 0.4764\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2698 - acc: 0.5083 - val_loss: 1.2905 - val_acc: 0.4782\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2684 - acc: 0.5083 - val_loss: 1.2892 - val_acc: 0.4782\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2671 - acc: 0.5093 - val_loss: 1.2879 - val_acc: 0.4782\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2657 - acc: 0.5106 - val_loss: 1.2866 - val_acc: 0.4782\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2644 - acc: 0.5115 - val_loss: 1.2853 - val_acc: 0.4818\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2631 - acc: 0.5125 - val_loss: 1.2841 - val_acc: 0.4818\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2618 - acc: 0.5141 - val_loss: 1.2828 - val_acc: 0.4836\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2605 - acc: 0.5157 - val_loss: 1.2816 - val_acc: 0.4836\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2592 - acc: 0.5167 - val_loss: 1.2804 - val_acc: 0.4836\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2579 - acc: 0.5173 - val_loss: 1.2792 - val_acc: 0.4836\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2567 - acc: 0.5179 - val_loss: 1.2780 - val_acc: 0.4818\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2554 - acc: 0.5183 - val_loss: 1.2768 - val_acc: 0.4836\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2542 - acc: 0.5183 - val_loss: 1.2756 - val_acc: 0.4836\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2530 - acc: 0.5192 - val_loss: 1.2745 - val_acc: 0.4836\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2518 - acc: 0.5202 - val_loss: 1.2733 - val_acc: 0.4836\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2506 - acc: 0.5212 - val_loss: 1.2722 - val_acc: 0.4836\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2494 - acc: 0.5212 - val_loss: 1.2711 - val_acc: 0.4855\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 20s 2s/step - loss: 1.2482 - acc: 0.5205 - val_loss: 1.2700 - val_acc: 0.4855\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2470 - acc: 0.5212 - val_loss: 1.2689 - val_acc: 0.4855\n"
     ]
    }
   ],
   "source": [
    "# get model and compile\n",
    "tf.keras.backend.clear_session()\n",
    "model = get_training_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
    "                     optimizer=\"adam\")\n",
    "\n",
    "# initialize wandb run\n",
    "wandb.init(entity='authors', project='swav-tf')\n",
    "\n",
    "# train \n",
    "history = model.fit(training_ds,\n",
    "                 validation_data=(testing_ds),\n",
    "                 epochs=100,\n",
    "                 callbacks=[WandbCallback(),\n",
    "                            early_stopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LstPmZTHEiVQ"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "7M_IdQv9EiVd",
    "outputId": "cfefe923-9445-4231-ac71-7407f5c32c7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 564ms/step - loss: 1.2689 - acc: 0.4855\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(testing_ds)\n",
    "wandb.log({'Test Accuracy': round(acc*100, 2)})"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Linear_Evaluation_Flower_Full_Dataset_Supervised.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
