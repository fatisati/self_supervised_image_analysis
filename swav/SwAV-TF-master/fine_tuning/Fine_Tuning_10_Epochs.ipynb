{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Fine Tuning on Flower Dataset",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/SwAV-TF/blob/master/fine_tuning/Fine_Tuning_10_Epochs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IyLUFcoFPCIO"
      },
      "source": [
        "# Imports and Setups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v8fMXBGWztKi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "82234dec-5534-4ce8-aab2-e9b78b12d060"
      },
      "source": [
        "!git clone https://github.com/ayulockin/SwAV-TF.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SwAV-TF'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 204 (delta 3), reused 0 (delta 0), pack-reused 198\u001b[K\n",
            "Receiving objects: 100% (204/204), 15.83 MiB | 13.22 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1O-8mYyD0CiP",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('SwAV-TF/utils')\n",
        "\n",
        "import multicrop_dataset\n",
        "import architecture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R1c99jQL0KMr",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "from imutils import paths\n",
        "\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)\n",
        "\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4sEtMAFTPQI5"
      },
      "source": [
        "#### W&B - Experiment Tracking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iwpgB1O9PUO5",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W8aCpiQUPZCO",
        "colab": {}
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7eaekTr10Yzn"
      },
      "source": [
        "## Restoring model weights from GCS Bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LROY2Mrn0wpY",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import get_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZiEZfPfG0TeL",
        "colab": {}
      },
      "source": [
        "feature_backbone_urlpath = \"https://storage.googleapis.com/swav-tf/feature_backbone_10_epochs.h5\"\n",
        "prototype_urlpath = \"https://storage.googleapis.com/swav-tf/projection_prototype_10_epochs.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7pEVJ4Y70isN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "32a467e8-ff9c-40bb-9041-79a1ba66c185"
      },
      "source": [
        "feature_backbone_weights = get_file('swav_feature_weights', feature_backbone_urlpath)\n",
        "prototype_weights = get_file('swav_prototype_projection_weights', prototype_urlpath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/swav-tf/feature_backbone_10_epochs.h5\n",
            "94584832/94582528 [==============================] - 3s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/swav-tf/projection_prototype_10_epochs.h5\n",
            "17907712/17900192 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vnhWEo8_12FK"
      },
      "source": [
        "## Dataset gathering and preparation\n",
        "\n",
        "We will be using only **10%** labeled data to fine-tune. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BAOhOFMs110h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "36597df2-64b9-4a45-f719-714b42ce46e9"
      },
      "source": [
        "# Gather Flowers dataset\n",
        "train_ds, extra_train_ds, validation_ds = tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split=[\"train[:10%]\", \"train[10%:85%]\", \"train[85%:]\"],\n",
        "    as_supervised=True\n",
        ")\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "@tf.function\n",
        "def scale_resize_image(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, (224, 224)) # Resizing to highest resolution used while training swav\n",
        "    return (image, label)\n",
        "\n",
        "training_ds = (\n",
        "    train_ds\n",
        "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "testing_ds = (\n",
        "    validation_ds\n",
        "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset tf_flowers/3.0.0 (download: 218.21 MiB, generated: Unknown size, total: 218.21 MiB) to /root/tensorflow_datasets/tf_flowers/3.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset tf_flowers is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDataset tf_flowers downloaded and prepared to /root/tensorflow_datasets/tf_flowers/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eqOBLHJa5Ztp"
      },
      "source": [
        "## Get SwAV architecture and Build Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Znqofzfr46-4",
        "colab": {}
      },
      "source": [
        "def get_linear_classifier():\n",
        "    # input placeholder\n",
        "    inputs = Input(shape=(224, 224, 3))\n",
        "    # get swav baseline model architecture\n",
        "    feature_backbone = architecture.get_resnet_backbone()\n",
        "    # load trained weights\n",
        "    feature_backbone.load_weights(feature_backbone_weights)\n",
        "    feature_backbone.trainable = False\n",
        "\n",
        "    x = feature_backbone(inputs, training=False)\n",
        "    outputs = Dense(5, activation=\"softmax\")(x)\n",
        "    linear_model = Model(inputs, outputs)\n",
        "\n",
        "    return linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qtt4jmzzxe8Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "d933e6b2-05b1-4782-bee5-47a4ae6cf715"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = get_linear_classifier()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "functional_1 (Functional)    (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 10245     \n",
            "=================================================================\n",
            "Total params: 23,597,957\n",
            "Trainable params: 10,245\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I0o5LHV0pCPu"
      },
      "source": [
        "## Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vECu62eyCdut",
        "colab": {}
      },
      "source": [
        "# Early Stopping to prevent overfitting\n",
        "early_stopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, verbose=2, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rp1fJIEYpFIC"
      },
      "source": [
        "# Without Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VEY1h0L2XjBJ"
      },
      "source": [
        "#### Warm Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RArUvFToDJKn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "8582e39c-127d-4877-a41b-56c488788966"
      },
      "source": [
        "# get model and compile\n",
        "tf.keras.backend.clear_session()\n",
        "model = get_linear_classifier()\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer='adam')\n",
        "\n",
        "# initialize wandb run\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train\n",
        "history = model.fit(training_ds,\n",
        "                 validation_data=(testing_ds),\n",
        "                 epochs=35,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "functional_1 (Functional)    (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 10245     \n",
            "=================================================================\n",
            "Total params: 23,597,957\n",
            "Trainable params: 10,245\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/2s8kynny\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/2s8kynny</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "6/6 [==============================] - 5s 806ms/step - loss: 2.6953 - acc: 0.1608 - val_loss: 1.8782 - val_acc: 0.2364\n",
            "Epoch 2/35\n",
            "6/6 [==============================] - 3s 568ms/step - loss: 2.0902 - acc: 0.3106 - val_loss: 1.7566 - val_acc: 0.2436\n",
            "Epoch 3/35\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 1.7659 - acc: 0.2561 - val_loss: 1.6900 - val_acc: 0.2909\n",
            "Epoch 4/35\n",
            "6/6 [==============================] - 3s 462ms/step - loss: 1.6749 - acc: 0.3324 - val_loss: 1.7713 - val_acc: 0.2600\n",
            "Epoch 5/35\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 1.6122 - acc: 0.3460 - val_loss: 1.6062 - val_acc: 0.2891\n",
            "Epoch 6/35\n",
            "6/6 [==============================] - 3s 475ms/step - loss: 1.5431 - acc: 0.3624 - val_loss: 1.6708 - val_acc: 0.2764\n",
            "Epoch 7/35\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.5336 - acc: 0.3624Restoring model weights from the end of the best epoch.\n",
            "6/6 [==============================] - 3s 475ms/step - loss: 1.5336 - acc: 0.3624 - val_loss: 1.6525 - val_acc: 0.2764\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fk_M5nFZeEOr",
        "colab": {}
      },
      "source": [
        "model.save('warmup.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UIgLm-WzahA8"
      },
      "source": [
        "#### Fine tune CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6H3r1pXThx0S",
        "colab": {}
      },
      "source": [
        " def get_classifier():\n",
        "    # input placeholder\n",
        "    inputs = Input(shape=(224, 224, 3))\n",
        "    # get swav baseline model architecture\n",
        "    feature_backbone = architecture.get_resnet_backbone()\n",
        "    # load trained weights\n",
        "    feature_backbone.load_weights(feature_backbone_weights)\n",
        "    feature_backbone.trainable = True\n",
        "\n",
        "    # load warmup model\n",
        "    warmup_model = tf.keras.models.load_model('warmup.h5')\n",
        "    # get trained output layer\n",
        "    last_layer = warmup_model.get_layer('dense')\n",
        "\n",
        "    \n",
        "    x = feature_backbone(inputs, training=False)\n",
        "    outputs = last_layer(x)\n",
        "    linear_model = Model(inputs, outputs)\n",
        "\n",
        "    return linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6EHIchqPm_qj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "8263251a-be05-4a08-809c-6d9bf5f93cfc"
      },
      "source": [
        "# get model and compile\n",
        "tf.keras.backend.clear_session()\n",
        "full_trainable_model = get_classifier()\n",
        "full_trainable_model.summary()\n",
        "\n",
        "full_trainable_model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer='adam')\n",
        "\n",
        "# initialize wandb\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train                                                        \n",
        "history = full_trainable_model.fit(training_ds,\n",
        "                 validation_data=(testing_ds),\n",
        "                 epochs=35,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "functional_1 (Functional)    (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 10245     \n",
            "=================================================================\n",
            "Total params: 23,597,957\n",
            "Trainable params: 23,544,837\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/5am1cm4y\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/5am1cm4y</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "      2/Unknown - 1s 304ms/step - loss: 5.0528 - acc: 0.2891WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2305s vs `on_train_batch_end` time: 0.3763s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2305s vs `on_train_batch_end` time: 0.3763s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 8s 1s/step - loss: 4.2599 - acc: 0.2807 - val_loss: 2.8384 - val_acc: 0.3291\n",
            "Epoch 2/35\n",
            "6/6 [==============================] - 6s 1s/step - loss: 2.0788 - acc: 0.4496 - val_loss: 1.7955 - val_acc: 0.4600\n",
            "Epoch 3/35\n",
            "6/6 [==============================] - 6s 1s/step - loss: 1.2194 - acc: 0.5395 - val_loss: 1.4361 - val_acc: 0.5327\n",
            "Epoch 4/35\n",
            "6/6 [==============================] - 5s 870ms/step - loss: 0.9144 - acc: 0.6730 - val_loss: 1.6796 - val_acc: 0.5164\n",
            "Epoch 5/35\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.8932 - acc: 0.6540Restoring model weights from the end of the best epoch.\n",
            "6/6 [==============================] - 5s 893ms/step - loss: 0.8932 - acc: 0.6540 - val_loss: 1.6108 - val_acc: 0.5291\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_AZUPjx5Q6Wc"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dWmYfCyjQx6Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d3a1b3c1-bed7-487f-d1dd-ad88167737b9"
      },
      "source": [
        "loss, acc = full_trainable_model.evaluate(testing_ds)\n",
        "wandb.log({'Test Accuracy': round(acc*100, 2)})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 2s 184ms/step - loss: 1.4361 - acc: 0.5327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "966mDKFhqsrk"
      },
      "source": [
        "# Training with Augmentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iPlQ3JKtq6j-"
      },
      "source": [
        "#### Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hACfOEyQnk4r",
        "colab": {}
      },
      "source": [
        "# Configs\n",
        "CROP_SIZE = 224\n",
        "MIN_SCALE = 0.5\n",
        "MAX_SCALE = 1.\n",
        "\n",
        "# Experimental options\n",
        "options = tf.data.Options()\n",
        "options.experimental_optimization.noop_elimination = True\n",
        "options.experimental_optimization.map_vectorization.enabled = True\n",
        "options.experimental_optimization.apply_default_optimizations = True\n",
        "options.experimental_deterministic = False\n",
        "options.experimental_threading.max_intra_op_parallelism = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hU2OZh1oTFaN",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def scale_image(image, label):\n",
        "\timage = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\treturn (image, label)\n",
        "\n",
        "@tf.function\n",
        "def random_apply(func, x, p):\n",
        "\treturn tf.cond(\n",
        "\t\ttf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "\t\t\t\ttf.cast(p, tf.float32)),\n",
        "\t\tlambda: func(x),\n",
        "\t\tlambda: x)\n",
        " \n",
        "@tf.function\n",
        "def random_resize_crop(image, label):\n",
        "  # Conditional resizing\n",
        "  image = tf.image.resize(image, (260, 260))\n",
        "  # Get the crop size for given min and max scale\n",
        "  size = tf.random.uniform(shape=(1,), minval=MIN_SCALE*260,\n",
        "\t\t          maxval=MAX_SCALE*260, dtype=tf.float32)\n",
        "  size = tf.cast(size, tf.int32)[0]\n",
        "  # Get the crop from the image\n",
        "  crop = tf.image.random_crop(image, (size,size,3))\n",
        "  crop_resize = tf.image.resize(crop, (CROP_SIZE, CROP_SIZE))\n",
        "  \n",
        "  return crop_resize, label\n",
        "\n",
        "@tf.function\n",
        "def tie_together(image, label):\n",
        "  # Scale the pixel values\n",
        "  image, label = scale_image(image , label)\n",
        "  # random horizontal flip\n",
        "  image = random_apply(tf.image.random_flip_left_right, image, p=0.5)\n",
        "  # Random resized crops\n",
        "  image, label = random_resize_crop(image, label)\n",
        "  \n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MLzlomx_d2iO",
        "colab": {}
      },
      "source": [
        "trainloader = (\n",
        "\ttrain_ds\n",
        "\t.shuffle(1024)\n",
        "\t.map(tie_together, num_parallel_calls=AUTO)\n",
        "\t.batch(BATCH_SIZE)\n",
        "\t.prefetch(AUTO)\n",
        ")\n",
        "\n",
        "trainloader = trainloader.with_options(options)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PBzTIQAqtsLu"
      },
      "source": [
        "#### Warmup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pat13QzdtsL3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "2dbb740d-9750-435e-d8c4-5fb040de0681"
      },
      "source": [
        "# get model and compile\n",
        "tf.keras.backend.clear_session()\n",
        "model = get_linear_classifier()\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer='adam')\n",
        "\n",
        "# initialize wandb run\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train\n",
        "history = model.fit(trainloader,\n",
        "                 validation_data=(testing_ds),\n",
        "                 epochs=35,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "functional_1 (Functional)    (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 10245     \n",
            "=================================================================\n",
            "Total params: 23,597,957\n",
            "Trainable params: 10,245\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/1i7yhwrx\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/1i7yhwrx</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "6/6 [==============================] - 4s 677ms/step - loss: 2.5339 - acc: 0.2125 - val_loss: 2.2990 - val_acc: 0.2600\n",
            "Epoch 2/35\n",
            "6/6 [==============================] - 4s 591ms/step - loss: 1.8990 - acc: 0.3270 - val_loss: 1.8746 - val_acc: 0.2618\n",
            "Epoch 3/35\n",
            "6/6 [==============================] - 4s 609ms/step - loss: 1.7228 - acc: 0.3324 - val_loss: 1.6946 - val_acc: 0.3164\n",
            "Epoch 4/35\n",
            "6/6 [==============================] - 3s 583ms/step - loss: 1.6566 - acc: 0.3842 - val_loss: 1.6715 - val_acc: 0.2618\n",
            "Epoch 5/35\n",
            "6/6 [==============================] - 4s 626ms/step - loss: 1.5973 - acc: 0.3215 - val_loss: 1.6127 - val_acc: 0.2745\n",
            "Epoch 6/35\n",
            "6/6 [==============================] - 3s 562ms/step - loss: 1.5181 - acc: 0.3624 - val_loss: 1.5963 - val_acc: 0.2782\n",
            "Epoch 7/35\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 1.5553 - acc: 0.3488 - val_loss: 1.6605 - val_acc: 0.3055\n",
            "Epoch 8/35\n",
            "6/6 [==============================] - 3s 559ms/step - loss: 1.5332 - acc: 0.3406 - val_loss: 1.5650 - val_acc: 0.2964\n",
            "Epoch 9/35\n",
            "6/6 [==============================] - 3s 488ms/step - loss: 1.5649 - acc: 0.3597 - val_loss: 1.6464 - val_acc: 0.2782\n",
            "Epoch 10/35\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.5523 - acc: 0.3569Restoring model weights from the end of the best epoch.\n",
            "6/6 [==============================] - 3s 493ms/step - loss: 1.5523 - acc: 0.3569 - val_loss: 1.7930 - val_acc: 0.2800\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hD-oqM7wslOr",
        "colab": {}
      },
      "source": [
        "model.save('warmup_augmentation.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q0IBzaXysj60"
      },
      "source": [
        "#### Fine tune CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OAn3v41qsj64",
        "colab": {}
      },
      "source": [
        " def get_classifier():\n",
        "    # input placeholder\n",
        "    inputs = Input(shape=(224, 224, 3))\n",
        "    # get swav baseline model architecture\n",
        "    feature_backbone = architecture.get_resnet_backbone()\n",
        "    # load trained weights\n",
        "    feature_backbone.load_weights(feature_backbone_weights)\n",
        "    feature_backbone.trainable = True\n",
        "\n",
        "    # load warmup model\n",
        "    warmup_model = tf.keras.models.load_model('warmup_augmentation.h5')\n",
        "    # get trained output layer\n",
        "    last_layer = warmup_model.get_layer('dense')\n",
        "\n",
        "    \n",
        "    x = feature_backbone(inputs, training=False)\n",
        "    outputs = last_layer(x)\n",
        "    linear_model = Model(inputs, outputs)\n",
        "\n",
        "    return linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3BoSzbemsj7F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "6087908e-678c-49b4-8ad4-cc973ec7a74b"
      },
      "source": [
        "# get model and compile\n",
        "tf.keras.backend.clear_session()\n",
        "full_trainable_model = get_classifier()\n",
        "full_trainable_model.summary()\n",
        "\n",
        "full_trainable_model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer='adam')\n",
        "\n",
        "# initialize wandb\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train                                                        \n",
        "history = full_trainable_model.fit(trainloader,\n",
        "                 validation_data=(testing_ds),\n",
        "                 epochs=35,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "functional_1 (Functional)    (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 10245     \n",
            "=================================================================\n",
            "Total params: 23,597,957\n",
            "Trainable params: 23,544,837\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/1e4urxrw\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/1e4urxrw</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "      2/Unknown - 1s 302ms/step - loss: 5.1523 - acc: 0.1953WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2202s vs `on_train_batch_end` time: 0.3816s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2202s vs `on_train_batch_end` time: 0.3816s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 7s 1s/step - loss: 4.6954 - acc: 0.2480 - val_loss: 2.2529 - val_acc: 0.3327\n",
            "Epoch 2/35\n",
            "6/6 [==============================] - 6s 1s/step - loss: 1.6760 - acc: 0.4741 - val_loss: 1.4216 - val_acc: 0.4655\n",
            "Epoch 3/35\n",
            "6/6 [==============================] - 5s 867ms/step - loss: 1.2600 - acc: 0.5286 - val_loss: 1.5094 - val_acc: 0.4364\n",
            "Epoch 4/35\n",
            "6/6 [==============================] - 6s 1s/step - loss: 1.2839 - acc: 0.5123 - val_loss: 1.3354 - val_acc: 0.5200\n",
            "Epoch 5/35\n",
            "6/6 [==============================] - 5s 872ms/step - loss: 1.1615 - acc: 0.5477 - val_loss: 1.4144 - val_acc: 0.5036\n",
            "Epoch 6/35\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.1305 - acc: 0.5150Restoring model weights from the end of the best epoch.\n",
            "6/6 [==============================] - 5s 882ms/step - loss: 1.1305 - acc: 0.5150 - val_loss: 1.3485 - val_acc: 0.5145\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FaKpRTQVXkF9"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zQAM4wjBXkGK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d3a3d688-3cfc-40d7-91c9-1d67ae0b188a"
      },
      "source": [
        "loss, acc = full_trainable_model.evaluate(testing_ds)\n",
        "wandb.log({'Test Accuracy': round(acc*100, 2)})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 2s 188ms/step - loss: 1.3354 - acc: 0.5200\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}