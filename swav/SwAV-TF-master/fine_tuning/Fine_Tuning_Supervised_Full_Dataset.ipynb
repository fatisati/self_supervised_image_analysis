{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vIjCKN58nCj0"
   },
   "source": [
    "# Imports and Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1c99jQL0KMr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "tf.random.set_seed(666)\n",
    "np.random.seed(666)\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_u5flNSnKMq"
   },
   "source": [
    "### W&B - Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "83g5TEyenP-M"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "sj0h9qQCnUBv",
    "outputId": "a83f1788-ee67-46c6-bb97-f1935b2280b7"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnhWEo8_12FK"
   },
   "source": [
    "## Dataset gathering and preparation\n",
    "\n",
    "We are using **85%** labeled training examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "BAOhOFMs110h",
    "outputId": "83f9d110-476d-4854-de5f-5cf9499cef40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset tf_flowers/3.0.0 (download: 218.21 MiB, generated: Unknown size, total: 218.21 MiB) to /root/tensorflow_datasets/tf_flowers/3.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Dataset tf_flowers is hosted on GCS. It will automatically be downloaded to your\n",
      "local data directory. If you'd instead prefer to read directly from our public\n",
      "GCS bucket (recommended if you're running on GCP), you can instead set\n",
      "data_dir=gs://tfds-data/datasets.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset tf_flowers downloaded and prepared to /root/tensorflow_datasets/tf_flowers/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Gather Flowers dataset\n",
    "train_ds, validation_ds = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:85%]\", \"train[85%:]\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "@tf.function\n",
    "def scale_resize_image(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, (224, 224)) # Resizing to highest resolution used while training swav\n",
    "    return (image, label)\n",
    "\n",
    "training_ds = (\n",
    "    train_ds\n",
    "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "testing_ds = (\n",
    "    validation_ds\n",
    "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqOBLHJa5Ztp"
   },
   "source": [
    "## ResNet50 base and a custom classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Znqofzfr46-4"
   },
   "outputs": [],
   "source": [
    "def get_training_model(trainable=False):\n",
    "    inputs = layers.Input(shape=(224, 224, 3))\n",
    "    EXTRACTOR = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False,\n",
    "        input_shape=(224, 224, 3))\n",
    "    EXTRACTOR.trainable = trainable\n",
    "    x = EXTRACTOR(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(5, activation=\"softmax\")(x)\n",
    "    classifier = models.Model(inputs=inputs, outputs=x)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "qtt4jmzzxe8Y",
    "outputId": "81994e6c-575a-4f30-ae02-cc9828720a63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 2s 0us/step\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 10245     \n",
      "=================================================================\n",
      "Total params: 23,597,957\n",
      "Trainable params: 10,245\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_training_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I0o5LHV0pCPu"
   },
   "source": [
    "### Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vECu62eyCdut"
   },
   "outputs": [],
   "source": [
    "# Early Stopping to prevent overfitting\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, verbose=2, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rp1fJIEYpFIC"
   },
   "source": [
    "# Without Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEY1h0L2XjBJ"
   },
   "source": [
    "### Warm Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RArUvFToDJKn",
    "outputId": "52055dd4-ac5e-491b-d830-56a246d4736b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/i4y0qcjk\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/i4y0qcjk</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "49/49 [==============================] - 12s 248ms/step - loss: 1.5814 - acc: 0.2885 - val_loss: 1.5539 - val_acc: 0.3109\n",
      "Epoch 2/35\n",
      "49/49 [==============================] - 11s 219ms/step - loss: 1.5063 - acc: 0.3599 - val_loss: 1.5196 - val_acc: 0.3364\n",
      "Epoch 3/35\n",
      "49/49 [==============================] - 11s 216ms/step - loss: 1.4792 - acc: 0.3849 - val_loss: 1.5015 - val_acc: 0.3527\n",
      "Epoch 4/35\n",
      "49/49 [==============================] - 11s 215ms/step - loss: 1.4616 - acc: 0.3962 - val_loss: 1.4877 - val_acc: 0.3655\n",
      "Epoch 5/35\n",
      "49/49 [==============================] - 11s 216ms/step - loss: 1.4480 - acc: 0.4058 - val_loss: 1.4758 - val_acc: 0.3764\n",
      "Epoch 6/35\n",
      "49/49 [==============================] - 11s 216ms/step - loss: 1.4365 - acc: 0.4141 - val_loss: 1.4651 - val_acc: 0.3782\n",
      "Epoch 7/35\n",
      "49/49 [==============================] - 11s 217ms/step - loss: 1.4263 - acc: 0.4215 - val_loss: 1.4552 - val_acc: 0.3891\n",
      "Epoch 8/35\n",
      "49/49 [==============================] - 11s 219ms/step - loss: 1.4171 - acc: 0.4266 - val_loss: 1.4460 - val_acc: 0.3945\n",
      "Epoch 9/35\n",
      "49/49 [==============================] - 11s 216ms/step - loss: 1.4086 - acc: 0.4327 - val_loss: 1.4373 - val_acc: 0.4109\n",
      "Epoch 10/35\n",
      "49/49 [==============================] - 11s 220ms/step - loss: 1.4007 - acc: 0.4375 - val_loss: 1.4291 - val_acc: 0.4145\n",
      "Epoch 11/35\n",
      "49/49 [==============================] - 11s 221ms/step - loss: 1.3933 - acc: 0.4401 - val_loss: 1.4213 - val_acc: 0.4182\n",
      "Epoch 12/35\n",
      "49/49 [==============================] - 11s 222ms/step - loss: 1.3863 - acc: 0.4446 - val_loss: 1.4140 - val_acc: 0.4164\n",
      "Epoch 13/35\n",
      "49/49 [==============================] - 11s 222ms/step - loss: 1.3797 - acc: 0.4484 - val_loss: 1.4070 - val_acc: 0.4182\n",
      "Epoch 14/35\n",
      "49/49 [==============================] - 11s 225ms/step - loss: 1.3734 - acc: 0.4510 - val_loss: 1.4004 - val_acc: 0.4236\n",
      "Epoch 15/35\n",
      "49/49 [==============================] - 11s 222ms/step - loss: 1.3674 - acc: 0.4554 - val_loss: 1.3941 - val_acc: 0.4291\n",
      "Epoch 16/35\n",
      "49/49 [==============================] - 11s 224ms/step - loss: 1.3616 - acc: 0.4587 - val_loss: 1.3880 - val_acc: 0.4364\n",
      "Epoch 17/35\n",
      "49/49 [==============================] - 11s 226ms/step - loss: 1.3561 - acc: 0.4603 - val_loss: 1.3822 - val_acc: 0.4418\n",
      "Epoch 18/35\n",
      "49/49 [==============================] - 11s 222ms/step - loss: 1.3508 - acc: 0.4625 - val_loss: 1.3767 - val_acc: 0.4436\n",
      "Epoch 19/35\n",
      "49/49 [==============================] - 11s 225ms/step - loss: 1.3457 - acc: 0.4660 - val_loss: 1.3714 - val_acc: 0.4455\n",
      "Epoch 20/35\n",
      "49/49 [==============================] - 11s 223ms/step - loss: 1.3408 - acc: 0.4673 - val_loss: 1.3663 - val_acc: 0.4509\n",
      "Epoch 21/35\n",
      "49/49 [==============================] - 11s 224ms/step - loss: 1.3360 - acc: 0.4689 - val_loss: 1.3614 - val_acc: 0.4564\n",
      "Epoch 22/35\n",
      "49/49 [==============================] - 11s 229ms/step - loss: 1.3314 - acc: 0.4721 - val_loss: 1.3567 - val_acc: 0.4600\n",
      "Epoch 23/35\n",
      "49/49 [==============================] - 11s 222ms/step - loss: 1.3270 - acc: 0.4760 - val_loss: 1.3522 - val_acc: 0.4636\n",
      "Epoch 24/35\n",
      "49/49 [==============================] - 11s 227ms/step - loss: 1.3227 - acc: 0.4760 - val_loss: 1.3478 - val_acc: 0.4691\n",
      "Epoch 25/35\n",
      "49/49 [==============================] - 11s 225ms/step - loss: 1.3185 - acc: 0.4798 - val_loss: 1.3436 - val_acc: 0.4709\n",
      "Epoch 26/35\n",
      "49/49 [==============================] - 11s 225ms/step - loss: 1.3145 - acc: 0.4827 - val_loss: 1.3395 - val_acc: 0.4727\n",
      "Epoch 27/35\n",
      "49/49 [==============================] - 11s 226ms/step - loss: 1.3105 - acc: 0.4872 - val_loss: 1.3356 - val_acc: 0.4745\n",
      "Epoch 28/35\n",
      "49/49 [==============================] - 11s 225ms/step - loss: 1.3067 - acc: 0.4881 - val_loss: 1.3318 - val_acc: 0.4782\n",
      "Epoch 29/35\n",
      "49/49 [==============================] - 11s 225ms/step - loss: 1.3029 - acc: 0.4888 - val_loss: 1.3281 - val_acc: 0.4800\n",
      "Epoch 30/35\n",
      "49/49 [==============================] - 11s 222ms/step - loss: 1.2993 - acc: 0.4910 - val_loss: 1.3245 - val_acc: 0.4782\n",
      "Epoch 31/35\n",
      "49/49 [==============================] - 11s 226ms/step - loss: 1.2958 - acc: 0.4926 - val_loss: 1.3210 - val_acc: 0.4818\n",
      "Epoch 32/35\n",
      "49/49 [==============================] - 11s 225ms/step - loss: 1.2923 - acc: 0.4974 - val_loss: 1.3177 - val_acc: 0.4836\n",
      "Epoch 33/35\n",
      "49/49 [==============================] - 11s 227ms/step - loss: 1.2889 - acc: 0.4994 - val_loss: 1.3144 - val_acc: 0.4836\n",
      "Epoch 34/35\n",
      "49/49 [==============================] - 11s 226ms/step - loss: 1.2856 - acc: 0.5029 - val_loss: 1.3112 - val_acc: 0.4855\n",
      "Epoch 35/35\n",
      "49/49 [==============================] - 11s 226ms/step - loss: 1.2824 - acc: 0.5048 - val_loss: 1.3081 - val_acc: 0.4855\n"
     ]
    }
   ],
   "source": [
    "# get model and compile\n",
    "model = get_training_model()\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
    "                     optimizer='adam')\n",
    "\n",
    "# initialize wandb run\n",
    "wandb.init(entity='authors', project='swav-tf')\n",
    "\n",
    "# train\n",
    "history = model.fit(training_ds,\n",
    "                 validation_data=testing_ds,\n",
    "                 epochs=35,\n",
    "                 callbacks=[WandbCallback(),\n",
    "                            early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fk_M5nFZeEOr"
   },
   "outputs": [],
   "source": [
    "model.save('warmup.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UIgLm-WzahA8"
   },
   "source": [
    "### Fine tune CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "id": "6EHIchqPm_qj",
    "outputId": "c7f3bceb-440a-459d-964a-38ee0b49c498"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/33umsi6u\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/33umsi6u</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "49/49 [==============================] - 34s 688ms/step - loss: 1.6727 - acc: 0.3170 - val_loss: 1.4672 - val_acc: 0.3818\n",
      "Epoch 2/35\n",
      "49/49 [==============================] - 33s 665ms/step - loss: 1.3820 - acc: 0.4279 - val_loss: 1.3446 - val_acc: 0.4691\n",
      "Epoch 3/35\n",
      "49/49 [==============================] - 33s 670ms/step - loss: 1.2861 - acc: 0.4846 - val_loss: 1.2509 - val_acc: 0.4909\n",
      "Epoch 4/35\n",
      "49/49 [==============================] - 33s 674ms/step - loss: 1.2162 - acc: 0.5212 - val_loss: 1.1584 - val_acc: 0.5364\n",
      "Epoch 5/35\n",
      "49/49 [==============================] - 33s 674ms/step - loss: 1.1146 - acc: 0.5679 - val_loss: 1.1189 - val_acc: 0.5727\n",
      "Epoch 6/35\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 0.9908 - acc: 0.6179 - val_loss: 1.0413 - val_acc: 0.6345\n",
      "Epoch 7/35\n",
      "49/49 [==============================] - 32s 652ms/step - loss: 0.9558 - acc: 0.6333 - val_loss: 1.0462 - val_acc: 0.6182\n",
      "Epoch 8/35\n",
      "49/49 [==============================] - 33s 682ms/step - loss: 0.9015 - acc: 0.6574 - val_loss: 0.9623 - val_acc: 0.6309\n",
      "Epoch 9/35\n",
      "49/49 [==============================] - 32s 652ms/step - loss: 0.8148 - acc: 0.6923 - val_loss: 1.0064 - val_acc: 0.6327\n",
      "Epoch 10/35\n",
      "49/49 [==============================] - 34s 684ms/step - loss: 0.7644 - acc: 0.7144 - val_loss: 0.9135 - val_acc: 0.6673\n",
      "Epoch 11/35\n",
      "49/49 [==============================] - 32s 654ms/step - loss: 0.7150 - acc: 0.7359 - val_loss: 0.9597 - val_acc: 0.6545\n",
      "Epoch 12/35\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.6792 - acc: 0.7343Restoring model weights from the end of the best epoch.\n",
      "49/49 [==============================] - 32s 656ms/step - loss: 0.6792 - acc: 0.7343 - val_loss: 0.9153 - val_acc: 0.6818\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "# prepare model and compiele\n",
    "model.layers[1].trainable = True\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
    "                     optimizer=tf.keras.optimizers.Adam(1e-5))\n",
    "\n",
    "# initialize wandb run\n",
    "wandb.init(entity='authors', project='swav-tf')\n",
    "\n",
    "# train\n",
    "history = model.fit(training_ds,\n",
    "                 validation_data=testing_ds,\n",
    "                 epochs=35,\n",
    "                 callbacks=[WandbCallback(),\n",
    "                            early_stopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vivDjXC0oF6m"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "cGkpf7bGoHgW",
    "outputId": "c4df5856-0ac9-4f2d-85da-d8d4c85ad3b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 144ms/step - loss: 0.9135 - acc: 0.6673\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(testing_ds)\n",
    "wandb.log({'Test Accuracy': round(acc*100, 2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "966mDKFhqsrk"
   },
   "source": [
    "# Training with Augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPlQ3JKtq6j-"
   },
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hACfOEyQnk4r"
   },
   "outputs": [],
   "source": [
    "# Configs\n",
    "CROP_SIZE = 224\n",
    "MIN_SCALE = 0.5\n",
    "MAX_SCALE = 1.\n",
    "\n",
    "# Experimental options\n",
    "options = tf.data.Options()\n",
    "options.experimental_optimization.noop_elimination = True\n",
    "options.experimental_optimization.map_vectorization.enabled = True\n",
    "options.experimental_optimization.apply_default_optimizations = True\n",
    "options.experimental_deterministic = False\n",
    "options.experimental_threading.max_intra_op_parallelism = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hU2OZh1oTFaN"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def scale_image(image, label):\n",
    "\timage = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\treturn (image, label)\n",
    "\n",
    "@tf.function\n",
    "def random_apply(func, x, p):\n",
    "\treturn tf.cond(\n",
    "\t\ttf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
    "\t\t\t\ttf.cast(p, tf.float32)),\n",
    "\t\tlambda: func(x),\n",
    "\t\tlambda: x)\n",
    " \n",
    "@tf.function\n",
    "def random_resize_crop(image, label):\n",
    "  # Conditional resizing\n",
    "  image = tf.image.resize(image, (260, 260))\n",
    "  # Get the crop size for given min and max scale\n",
    "  size = tf.random.uniform(shape=(1,), minval=MIN_SCALE*260,\n",
    "\t\t          maxval=MAX_SCALE*260, dtype=tf.float32)\n",
    "  size = tf.cast(size, tf.int32)[0]\n",
    "  # Get the crop from the image\n",
    "  crop = tf.image.random_crop(image, (size,size,3))\n",
    "  crop_resize = tf.image.resize(crop, (CROP_SIZE, CROP_SIZE))\n",
    "  \n",
    "  return crop_resize, label\n",
    "\n",
    "@tf.function\n",
    "def tie_together(image, label):\n",
    "  # Scale the pixel values\n",
    "  image, label = scale_image(image , label)\n",
    "  # random horizontal flip\n",
    "  image = random_apply(tf.image.random_flip_left_right, image, p=0.5)\n",
    "  # Random resized crops\n",
    "  image, label = random_resize_crop(image, label)\n",
    "  \n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MLzlomx_d2iO"
   },
   "outputs": [],
   "source": [
    "trainloader = (\n",
    "\ttrain_ds\n",
    "\t.shuffle(1024)\n",
    "\t.map(tie_together, num_parallel_calls=AUTO)\n",
    "\t.batch(BATCH_SIZE)\n",
    "\t.prefetch(AUTO)\n",
    ")\n",
    "\n",
    "trainloader = trainloader.with_options(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PBzTIQAqtsLu"
   },
   "source": [
    "### Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "colab_type": "code",
    "id": "Pat13QzdtsL3",
    "outputId": "43a341f9-50b7-499b-bfa4-8bdee93b538d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/nvbd9gx6\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/nvbd9gx6</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "49/49 [==============================] - 11s 232ms/step - loss: 1.5935 - acc: 0.2657 - val_loss: 1.5471 - val_acc: 0.3036\n",
      "Epoch 2/35\n",
      "49/49 [==============================] - 11s 217ms/step - loss: 1.5420 - acc: 0.3426 - val_loss: 1.5299 - val_acc: 0.3436\n",
      "Epoch 3/35\n",
      "49/49 [==============================] - 11s 219ms/step - loss: 1.5271 - acc: 0.3561 - val_loss: 1.5070 - val_acc: 0.3436\n",
      "Epoch 4/35\n",
      "49/49 [==============================] - 11s 219ms/step - loss: 1.5095 - acc: 0.3561 - val_loss: 1.4881 - val_acc: 0.3636\n",
      "Epoch 5/35\n",
      "49/49 [==============================] - 11s 222ms/step - loss: 1.5013 - acc: 0.3644 - val_loss: 1.4764 - val_acc: 0.3800\n",
      "Epoch 6/35\n",
      "49/49 [==============================] - 11s 221ms/step - loss: 1.4851 - acc: 0.3718 - val_loss: 1.4602 - val_acc: 0.3964\n",
      "Epoch 7/35\n",
      "49/49 [==============================] - 10s 210ms/step - loss: 1.4782 - acc: 0.3785 - val_loss: 1.5021 - val_acc: 0.3582\n",
      "Epoch 8/35\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.4706 - acc: 0.3795Restoring model weights from the end of the best epoch.\n",
      "49/49 [==============================] - 11s 215ms/step - loss: 1.4706 - acc: 0.3795 - val_loss: 1.4648 - val_acc: 0.3927\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "# get model and compile\n",
    "model = get_training_model()\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
    "                     optimizer='adam')\n",
    "\n",
    "# initialize wandb run\n",
    "wandb.init(entity='authors', project='swav-tf')\n",
    "\n",
    "# train\n",
    "history = model.fit(trainloader,\n",
    "                 validation_data=testing_ds,\n",
    "                 epochs=35,\n",
    "                 callbacks=[WandbCallback(),\n",
    "                            early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hD-oqM7wslOr"
   },
   "outputs": [],
   "source": [
    "model.save('warmup_augmentation.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q0IBzaXysj60"
   },
   "source": [
    "### Fine tune CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "colab_type": "code",
    "id": "3BoSzbemsj7F",
    "outputId": "4b686284-ca7e-45ff-c8da-af5fafb0db26"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/1nhh7egp\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/1nhh7egp</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "49/49 [==============================] - 33s 671ms/step - loss: 1.6167 - acc: 0.2792 - val_loss: 1.5346 - val_acc: 0.3418\n",
      "Epoch 2/35\n",
      "49/49 [==============================] - 31s 632ms/step - loss: 1.5041 - acc: 0.3535 - val_loss: 1.7565 - val_acc: 0.1782\n",
      "Epoch 3/35\n",
      "49/49 [==============================] - 33s 664ms/step - loss: 1.4996 - acc: 0.3683 - val_loss: 1.3907 - val_acc: 0.4509\n",
      "Epoch 4/35\n",
      "49/49 [==============================] - 33s 671ms/step - loss: 1.4181 - acc: 0.4093 - val_loss: 1.3449 - val_acc: 0.4364\n",
      "Epoch 5/35\n",
      "49/49 [==============================] - 33s 672ms/step - loss: 1.3706 - acc: 0.4311 - val_loss: 1.3143 - val_acc: 0.4927\n",
      "Epoch 6/35\n",
      "49/49 [==============================] - 32s 646ms/step - loss: 1.3665 - acc: 0.4349 - val_loss: 1.3287 - val_acc: 0.4636\n",
      "Epoch 7/35\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 1.2956 - acc: 0.4715 - val_loss: 1.2758 - val_acc: 0.4691\n",
      "Epoch 8/35\n",
      "49/49 [==============================] - 33s 674ms/step - loss: 1.2930 - acc: 0.4683 - val_loss: 1.2572 - val_acc: 0.5036\n",
      "Epoch 9/35\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 1.2202 - acc: 0.5138 - val_loss: 1.1707 - val_acc: 0.5491\n",
      "Epoch 10/35\n",
      "49/49 [==============================] - 33s 680ms/step - loss: 1.1907 - acc: 0.5157 - val_loss: 1.1707 - val_acc: 0.4909\n",
      "Epoch 11/35\n",
      "49/49 [==============================] - 32s 652ms/step - loss: 1.1072 - acc: 0.5663 - val_loss: 1.2217 - val_acc: 0.5400\n",
      "Epoch 12/35\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 1.0897 - acc: 0.5744 - val_loss: 0.8830 - val_acc: 0.6673\n",
      "Epoch 13/35\n",
      "49/49 [==============================] - 32s 653ms/step - loss: 0.9965 - acc: 0.6147 - val_loss: 0.8842 - val_acc: 0.6636\n",
      "Epoch 14/35\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.9851 - acc: 0.6263 - val_loss: 0.8476 - val_acc: 0.7273\n",
      "Epoch 15/35\n",
      "49/49 [==============================] - 33s 683ms/step - loss: 0.8858 - acc: 0.6567 - val_loss: 0.7615 - val_acc: 0.7509\n",
      "Epoch 16/35\n",
      "49/49 [==============================] - 32s 653ms/step - loss: 0.8617 - acc: 0.6696 - val_loss: 0.8661 - val_acc: 0.6909\n",
      "Epoch 17/35\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.8522 - acc: 0.6753Restoring model weights from the end of the best epoch.\n",
      "49/49 [==============================] - 32s 657ms/step - loss: 0.8522 - acc: 0.6753 - val_loss: 0.8929 - val_acc: 0.6909\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "# prepare model and compiele\n",
    "model.layers[1].trainable = True\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
    "                     optimizer=tf.keras.optimizers.Adam(1e-5))\n",
    "\n",
    "# initialize wandb run\n",
    "wandb.init(entity='authors', project='swav-tf')\n",
    "\n",
    "# train\n",
    "history = model.fit(trainloader,\n",
    "                 validation_data=testing_ds,\n",
    "                 epochs=35,\n",
    "                 callbacks=[WandbCallback(),\n",
    "                            early_stopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghvNZKDZuvmC"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "royxn_DLuvmF",
    "outputId": "f4ff7815-6d88-4977-8f31-115d92e59e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 146ms/step - loss: 0.7615 - acc: 0.7509\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(testing_ds)\n",
    "wandb.log({'Test Accuracy': round(acc*100, 2)})"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Fine_Tuning_on_Flower_Full_Dataset_Supervised.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
