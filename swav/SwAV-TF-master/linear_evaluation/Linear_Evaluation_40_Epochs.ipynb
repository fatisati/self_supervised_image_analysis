{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Linear_Evaluation_on_Flower_Dataset(40_epochs).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/SwAV-TF/blob/master/linear_evaluation/Linear_Evaluation_40_Epochs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mQhyBFsMg_ye"
      },
      "source": [
        "# Imports and Setups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v8fMXBGWztKi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "aa680a73-8f05-42c8-ce4d-df313c29521c"
      },
      "source": [
        "!git clone https://github.com/ayulockin/SwAV-TF.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SwAV-TF'...\n",
            "remote: Enumerating objects: 198, done.\u001b[K\n",
            "Receiving objects:   0% (1/198)   \rReceiving objects:   1% (2/198)   \rReceiving objects:   2% (4/198)   \rReceiving objects:   3% (6/198)   \rReceiving objects:   4% (8/198)   \rReceiving objects:   5% (10/198)   \rReceiving objects:   6% (12/198)   \rReceiving objects:   7% (14/198)   \rReceiving objects:   8% (16/198)   \rReceiving objects:   9% (18/198)   \rReceiving objects:  10% (20/198)   \rReceiving objects:  11% (22/198)   \rReceiving objects:  12% (24/198)   \rReceiving objects:  13% (26/198)   \rReceiving objects:  14% (28/198)   \rReceiving objects:  15% (30/198)   \rReceiving objects:  16% (32/198)   \rReceiving objects:  17% (34/198)   \rReceiving objects:  18% (36/198)   \rReceiving objects:  19% (38/198)   \rReceiving objects:  20% (40/198)   \rReceiving objects:  21% (42/198)   \rReceiving objects:  22% (44/198)   \rReceiving objects:  23% (46/198)   \rReceiving objects:  24% (48/198)   \rReceiving objects:  25% (50/198)   \rReceiving objects:  26% (52/198)   \rReceiving objects:  27% (54/198)   \rReceiving objects:  28% (56/198)   \rReceiving objects:  29% (58/198)   \rReceiving objects:  30% (60/198)   \rReceiving objects:  31% (62/198)   \rReceiving objects:  32% (64/198)   \rReceiving objects:  33% (66/198)   \rReceiving objects:  34% (68/198)   \rReceiving objects:  35% (70/198)   \rReceiving objects:  36% (72/198)   \rReceiving objects:  37% (74/198)   \rReceiving objects:  38% (76/198)   \rReceiving objects:  39% (78/198)   \rReceiving objects:  40% (80/198)   \rReceiving objects:  41% (82/198)   \rReceiving objects:  42% (84/198)   \rReceiving objects:  43% (86/198)   \rReceiving objects:  44% (88/198)   \rReceiving objects:  45% (90/198)   \rReceiving objects:  46% (92/198)   \rReceiving objects:  47% (94/198)   \rReceiving objects:  48% (96/198)   \rReceiving objects:  49% (98/198)   \rReceiving objects:  50% (99/198)   \rReceiving objects:  51% (101/198)   \rReceiving objects:  52% (103/198)   \rReceiving objects:  53% (105/198)   \rReceiving objects:  54% (107/198)   \rReceiving objects:  55% (109/198)   \rReceiving objects:  56% (111/198)   \rReceiving objects:  57% (113/198)   \rReceiving objects:  58% (115/198)   \rReceiving objects:  59% (117/198)   \rReceiving objects:  60% (119/198)   \rReceiving objects:  61% (121/198)   \rReceiving objects:  62% (123/198)   \rReceiving objects:  63% (125/198)   \rReceiving objects:  64% (127/198)   \rReceiving objects:  65% (129/198)   \rReceiving objects:  66% (131/198)   \rReceiving objects:  67% (133/198)   \rReceiving objects:  68% (135/198)   \rReceiving objects:  69% (137/198)   \rReceiving objects:  70% (139/198)   \rReceiving objects:  71% (141/198)   \rReceiving objects:  72% (143/198)   \rReceiving objects:  73% (145/198)   \rReceiving objects:  74% (147/198)   \rReceiving objects:  75% (149/198)   \rReceiving objects:  76% (151/198)   \rReceiving objects:  77% (153/198)   \rReceiving objects:  78% (155/198)   \rReceiving objects:  79% (157/198)   \rReceiving objects:  80% (159/198)   \rReceiving objects:  81% (161/198)   \rReceiving objects:  82% (163/198)   \rReceiving objects:  83% (165/198)   \rReceiving objects:  84% (167/198)   \rReceiving objects:  85% (169/198)   \rReceiving objects:  86% (171/198)   \rReceiving objects:  87% (173/198)   \rReceiving objects:  88% (175/198)   \rReceiving objects:  89% (177/198)   \rReceiving objects:  90% (179/198)   \rReceiving objects:  91% (181/198)   \rReceiving objects:  92% (183/198)   \rReceiving objects:  93% (185/198)   \rReceiving objects:  94% (187/198)   \rReceiving objects:  95% (189/198)   \rReceiving objects:  96% (191/198)   \rReceiving objects:  97% (193/198)   \rremote: Total 198 (delta 0), reused 0 (delta 0), pack-reused 198\u001b[K\n",
            "Receiving objects:  98% (195/198)   \rReceiving objects:  99% (197/198)   \rReceiving objects: 100% (198/198)   \rReceiving objects: 100% (198/198), 15.82 MiB | 34.02 MiB/s, done.\n",
            "Resolving deltas:   0% (0/90)   \rResolving deltas:   1% (1/90)   \rResolving deltas:   2% (2/90)   \rResolving deltas:   3% (3/90)   \rResolving deltas:  48% (44/90)   \rResolving deltas:  52% (47/90)   \rResolving deltas:  55% (50/90)   \rResolving deltas:  57% (52/90)   \rResolving deltas:  58% (53/90)   \rResolving deltas:  64% (58/90)   \rResolving deltas:  66% (60/90)   \rResolving deltas:  73% (66/90)   \rResolving deltas:  74% (67/90)   \rResolving deltas:  75% (68/90)   \rResolving deltas:  76% (69/90)   \rResolving deltas:  77% (70/90)   \rResolving deltas:  78% (71/90)   \rResolving deltas:  82% (74/90)   \rResolving deltas:  83% (75/90)   \rResolving deltas:  91% (82/90)   \rResolving deltas:  98% (89/90)   \rResolving deltas: 100% (90/90)   \rResolving deltas: 100% (90/90), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1O-8mYyD0CiP",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('SwAV-TF/utils')\n",
        "\n",
        "import multicrop_dataset\n",
        "import architecture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R1c99jQL0KMr",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "from imutils import paths\n",
        "\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)\n",
        "\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ch7kShibnJv-"
      },
      "source": [
        "#### W&B - Experiment Tracking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SaUmsxfJnGvz",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ATFdYM6TmxuQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "e50256a2-8f19-4748-cefa-a3ee9859a839"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://app.wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Not authenticated.  Copy a key from https://app.wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "API Key: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7eaekTr10Yzn"
      },
      "source": [
        "#### Restoring model weights from GCS Bucket - Model trained for 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LROY2Mrn0wpY",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import get_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZiEZfPfG0TeL",
        "colab": {}
      },
      "source": [
        "feature_backbone_urlpath = \"https://storage.googleapis.com/swav-tf/feature_backbone_40_epochs.h5\"\n",
        "prototype_urlpath = \"https://storage.googleapis.com/swav-tf/projection_prototype_40_epochs.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7pEVJ4Y70isN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "6bb31e81-870b-47ea-9336-87eacc1b37ee"
      },
      "source": [
        "feature_backbone_weights = get_file('swav_feature_weights', feature_backbone_urlpath)\n",
        "prototype_weights = get_file('swav_prototype_projection_weights', prototype_urlpath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/swav-tf/feature_backbone_40_epochs.h5\n",
            "94584832/94583160 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/swav-tf/projection_prototype_40_epochs.h5\n",
            "8839168/8831904 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vnhWEo8_12FK"
      },
      "source": [
        "#### Dataset gathering and preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BAOhOFMs110h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "06ccdc27-1bf7-450a-ecfe-c104bf0fa29b"
      },
      "source": [
        "# Gather Flowers dataset\n",
        "train_ds, validation_ds = tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split=[\"train[:85%]\", \"train[85%:]\"],\n",
        "    as_supervised=True\n",
        ")\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "@tf.function\n",
        "def scale_resize_image(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, (224, 224)) # Resizing to highest resolution used while training swav\n",
        "    return (image, label)\n",
        "\n",
        "training_ds = (\n",
        "    train_ds\n",
        "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "testing_ds = (\n",
        "    validation_ds\n",
        "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset tf_flowers is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset tf_flowers/3.0.0 (download: 218.21 MiB, generated: Unknown size, total: 218.21 MiB) to /root/tensorflow_datasets/tf_flowers/3.0.0...\u001b[0m\n",
            "\u001b[1mDataset tf_flowers downloaded and prepared to /root/tensorflow_datasets/tf_flowers/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eqOBLHJa5Ztp"
      },
      "source": [
        "#### Get SwAV architecture and Build Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Znqofzfr46-4",
        "colab": {}
      },
      "source": [
        "def get_linear_classifier(alpha=1e-6):\n",
        "    # input placeholder\n",
        "    inputs = Input(shape=(224, 224, 3))\n",
        "    # get swav baseline model architecture\n",
        "    feature_backbone = architecture.get_resnet_backbone()\n",
        "    # load trained weights\n",
        "    feature_backbone.load_weights(feature_backbone_weights)\n",
        "    feature_backbone.trainable = False\n",
        "\n",
        "    x = feature_backbone(inputs, training=False)\n",
        "    outputs = Dense(5, activation=\"softmax\", \n",
        "                    kernel_regularizer=tf.keras.regularizers.L2(alpha))(x)\n",
        "    linear_model = Model(inputs, outputs)\n",
        "\n",
        "    return linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qtt4jmzzxe8Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "402153e5-edd9-489b-8484-4979e5b1a297"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = get_linear_classifier()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "functional_1 (Functional)    (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 10245     \n",
            "=================================================================\n",
            "Total params: 23,597,957\n",
            "Trainable params: 10,245\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I0o5LHV0pCPu"
      },
      "source": [
        "#### Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vECu62eyCdut",
        "colab": {}
      },
      "source": [
        "# Early Stopping to prevent overfitting\n",
        "early_stopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, verbose=2, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rp1fJIEYpFIC"
      },
      "source": [
        "# Training Linear Classifier - Without Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CutzK-izvyyV"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RArUvFToDJKn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2db7aee6-4891-4668-cc08-062d889d8bb8"
      },
      "source": [
        "# get model and compile\n",
        "tf.keras.backend.clear_session()\n",
        "model = get_linear_classifier(alpha=1e-6)\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer=\"adam\")\n",
        "\n",
        "# initialize wandb run\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train \n",
        "history = model.fit(training_ds,\n",
        "                 validation_data=(testing_ds),\n",
        "                 epochs=100,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "functional_1 (Functional)    (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 10245     \n",
            "=================================================================\n",
            "Total params: 23,597,957\n",
            "Trainable params: 10,245\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/qz5o535c\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/qz5o535c</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 12s 907ms/step - loss: 2.1888 - acc: 0.2301 - val_loss: 2.0296 - val_acc: 0.2073\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 10s 786ms/step - loss: 1.7469 - acc: 0.2641 - val_loss: 1.7927 - val_acc: 0.2473\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 10s 791ms/step - loss: 1.6424 - acc: 0.2811 - val_loss: 1.6185 - val_acc: 0.2527\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 10s 793ms/step - loss: 1.5753 - acc: 0.3135 - val_loss: 1.5742 - val_acc: 0.2927\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 10s 759ms/step - loss: 1.5509 - acc: 0.3234 - val_loss: 1.5816 - val_acc: 0.2945\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 11s 818ms/step - loss: 1.5428 - acc: 0.3279 - val_loss: 1.5479 - val_acc: 0.2927\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 11s 844ms/step - loss: 1.5246 - acc: 0.3478 - val_loss: 1.5457 - val_acc: 0.3073\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 11s 837ms/step - loss: 1.5168 - acc: 0.3510 - val_loss: 1.5403 - val_acc: 0.3055\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 11s 851ms/step - loss: 1.5105 - acc: 0.3564 - val_loss: 1.5282 - val_acc: 0.3091\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 11s 865ms/step - loss: 1.5002 - acc: 0.3651 - val_loss: 1.5217 - val_acc: 0.3127\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.4910 - acc: 0.3692 - val_loss: 1.5155 - val_acc: 0.3291\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 12s 892ms/step - loss: 1.4830 - acc: 0.3724 - val_loss: 1.5091 - val_acc: 0.3291\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.4751 - acc: 0.3760 - val_loss: 1.5027 - val_acc: 0.3382\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 11s 871ms/step - loss: 1.4670 - acc: 0.3821 - val_loss: 1.4967 - val_acc: 0.3418\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 11s 869ms/step - loss: 1.4592 - acc: 0.3862 - val_loss: 1.4910 - val_acc: 0.3473\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 11s 873ms/step - loss: 1.4515 - acc: 0.3907 - val_loss: 1.4857 - val_acc: 0.3509\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.4440 - acc: 0.3971 - val_loss: 1.4806 - val_acc: 0.3545\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.4367 - acc: 0.4029 - val_loss: 1.4757 - val_acc: 0.3600\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.4296 - acc: 0.4058 - val_loss: 1.4712 - val_acc: 0.3764\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 11s 876ms/step - loss: 1.4226 - acc: 0.4090 - val_loss: 1.4670 - val_acc: 0.3782\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.4158 - acc: 0.4160 - val_loss: 1.4630 - val_acc: 0.3836\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 1.4091 - acc: 0.4212 - val_loss: 1.4594 - val_acc: 0.3945\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 11s 873ms/step - loss: 1.4026 - acc: 0.4256 - val_loss: 1.4560 - val_acc: 0.3891\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 11s 872ms/step - loss: 1.3962 - acc: 0.4282 - val_loss: 1.4528 - val_acc: 0.3927\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 11s 881ms/step - loss: 1.3901 - acc: 0.4340 - val_loss: 1.4498 - val_acc: 0.3945\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.3840 - acc: 0.4362 - val_loss: 1.4468 - val_acc: 0.3964\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 11s 876ms/step - loss: 1.3781 - acc: 0.4404 - val_loss: 1.4440 - val_acc: 0.3964\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 11s 879ms/step - loss: 1.3724 - acc: 0.4442 - val_loss: 1.4412 - val_acc: 0.3945\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 11s 879ms/step - loss: 1.3667 - acc: 0.4474 - val_loss: 1.4384 - val_acc: 0.3945\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 1.3612 - acc: 0.4500 - val_loss: 1.4357 - val_acc: 0.3982\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 1.3558 - acc: 0.4554 - val_loss: 1.4329 - val_acc: 0.4036\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 1.3506 - acc: 0.4567 - val_loss: 1.4302 - val_acc: 0.4073\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 1.3454 - acc: 0.4603 - val_loss: 1.4274 - val_acc: 0.4073\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 11s 879ms/step - loss: 1.3404 - acc: 0.4612 - val_loss: 1.4247 - val_acc: 0.4073\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.3355 - acc: 0.4657 - val_loss: 1.4221 - val_acc: 0.4127\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 1.3307 - acc: 0.4670 - val_loss: 1.4195 - val_acc: 0.4127\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.3260 - acc: 0.4686 - val_loss: 1.4169 - val_acc: 0.4145\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.3213 - acc: 0.4712 - val_loss: 1.4144 - val_acc: 0.4164\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.3168 - acc: 0.4734 - val_loss: 1.4119 - val_acc: 0.4182\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.3124 - acc: 0.4769 - val_loss: 1.4095 - val_acc: 0.4182\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.3080 - acc: 0.4782 - val_loss: 1.4072 - val_acc: 0.4182\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 11s 871ms/step - loss: 1.3038 - acc: 0.4798 - val_loss: 1.4049 - val_acc: 0.4182\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 1.2996 - acc: 0.4821 - val_loss: 1.4026 - val_acc: 0.4200\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.2955 - acc: 0.4840 - val_loss: 1.4004 - val_acc: 0.4236\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 11s 881ms/step - loss: 1.2915 - acc: 0.4878 - val_loss: 1.3983 - val_acc: 0.4218\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 11s 873ms/step - loss: 1.2875 - acc: 0.4907 - val_loss: 1.3962 - val_acc: 0.4236\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 11s 870ms/step - loss: 1.2837 - acc: 0.4923 - val_loss: 1.3942 - val_acc: 0.4236\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 12s 888ms/step - loss: 1.2799 - acc: 0.4949 - val_loss: 1.3922 - val_acc: 0.4255\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 12s 887ms/step - loss: 1.2761 - acc: 0.4971 - val_loss: 1.3902 - val_acc: 0.4236\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 1.2725 - acc: 0.4984 - val_loss: 1.3883 - val_acc: 0.4236\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.2689 - acc: 0.4990 - val_loss: 1.3864 - val_acc: 0.4273\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.2653 - acc: 0.5010 - val_loss: 1.3845 - val_acc: 0.4273\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.2618 - acc: 0.5048 - val_loss: 1.3827 - val_acc: 0.4309\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.2584 - acc: 0.5074 - val_loss: 1.3808 - val_acc: 0.4309\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 1.2550 - acc: 0.5090 - val_loss: 1.3790 - val_acc: 0.4327\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.2517 - acc: 0.5128 - val_loss: 1.3773 - val_acc: 0.4327\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 11s 876ms/step - loss: 1.2484 - acc: 0.5154 - val_loss: 1.3755 - val_acc: 0.4327\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 1.2452 - acc: 0.5144 - val_loss: 1.3737 - val_acc: 0.4345\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 11s 879ms/step - loss: 1.2420 - acc: 0.5160 - val_loss: 1.3720 - val_acc: 0.4345\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.2389 - acc: 0.5186 - val_loss: 1.3702 - val_acc: 0.4327\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 1.2358 - acc: 0.5208 - val_loss: 1.3684 - val_acc: 0.4309\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 11s 874ms/step - loss: 1.2327 - acc: 0.5221 - val_loss: 1.3667 - val_acc: 0.4291\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.2297 - acc: 0.5250 - val_loss: 1.3649 - val_acc: 0.4309\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 11s 884ms/step - loss: 1.2267 - acc: 0.5250 - val_loss: 1.3632 - val_acc: 0.4291\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 11s 876ms/step - loss: 1.2237 - acc: 0.5253 - val_loss: 1.3614 - val_acc: 0.4327\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.2207 - acc: 0.5266 - val_loss: 1.3596 - val_acc: 0.4364\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 11s 874ms/step - loss: 1.2178 - acc: 0.5292 - val_loss: 1.3578 - val_acc: 0.4364\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 11s 874ms/step - loss: 1.2149 - acc: 0.5304 - val_loss: 1.3561 - val_acc: 0.4382\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 11s 881ms/step - loss: 1.2120 - acc: 0.5317 - val_loss: 1.3543 - val_acc: 0.4364\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.2092 - acc: 0.5346 - val_loss: 1.3525 - val_acc: 0.4382\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 11s 873ms/step - loss: 1.2063 - acc: 0.5349 - val_loss: 1.3507 - val_acc: 0.4400\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 11s 874ms/step - loss: 1.2035 - acc: 0.5375 - val_loss: 1.3490 - val_acc: 0.4400\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.2007 - acc: 0.5391 - val_loss: 1.3472 - val_acc: 0.4400\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 11s 884ms/step - loss: 1.1979 - acc: 0.5385 - val_loss: 1.3455 - val_acc: 0.4418\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 11s 879ms/step - loss: 1.1951 - acc: 0.5397 - val_loss: 1.3437 - val_acc: 0.4418\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 1.1924 - acc: 0.5413 - val_loss: 1.3420 - val_acc: 0.4418\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 1.1896 - acc: 0.5426 - val_loss: 1.3403 - val_acc: 0.4473\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 11s 881ms/step - loss: 1.1869 - acc: 0.5433 - val_loss: 1.3387 - val_acc: 0.4491\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.1842 - acc: 0.5446 - val_loss: 1.3371 - val_acc: 0.4491\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.1815 - acc: 0.5468 - val_loss: 1.3355 - val_acc: 0.4509\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 11s 870ms/step - loss: 1.1788 - acc: 0.5478 - val_loss: 1.3339 - val_acc: 0.4509\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 11s 871ms/step - loss: 1.1762 - acc: 0.5484 - val_loss: 1.3324 - val_acc: 0.4527\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 11s 876ms/step - loss: 1.1736 - acc: 0.5500 - val_loss: 1.3308 - val_acc: 0.4527\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 11s 879ms/step - loss: 1.1709 - acc: 0.5513 - val_loss: 1.3294 - val_acc: 0.4582\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 11s 883ms/step - loss: 1.1683 - acc: 0.5519 - val_loss: 1.3280 - val_acc: 0.4600\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 1.1657 - acc: 0.5548 - val_loss: 1.3266 - val_acc: 0.4655\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 1.1632 - acc: 0.5554 - val_loss: 1.3252 - val_acc: 0.4691\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 1.1606 - acc: 0.5583 - val_loss: 1.3239 - val_acc: 0.4709\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 1.1581 - acc: 0.5583 - val_loss: 1.3226 - val_acc: 0.4709\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.1556 - acc: 0.5609 - val_loss: 1.3213 - val_acc: 0.4727\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.1531 - acc: 0.5615 - val_loss: 1.3201 - val_acc: 0.4691\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 12s 886ms/step - loss: 1.1506 - acc: 0.5631 - val_loss: 1.3190 - val_acc: 0.4691\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 1.1482 - acc: 0.5660 - val_loss: 1.3178 - val_acc: 0.4691\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.1458 - acc: 0.5673 - val_loss: 1.3167 - val_acc: 0.4709\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 11s 881ms/step - loss: 1.1434 - acc: 0.5686 - val_loss: 1.3156 - val_acc: 0.4709\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.1410 - acc: 0.5696 - val_loss: 1.3146 - val_acc: 0.4709\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 11s 874ms/step - loss: 1.1386 - acc: 0.5712 - val_loss: 1.3136 - val_acc: 0.4745\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 12s 888ms/step - loss: 1.1363 - acc: 0.5708 - val_loss: 1.3126 - val_acc: 0.4782\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.1339 - acc: 0.5724 - val_loss: 1.3116 - val_acc: 0.4818\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.1316 - acc: 0.5734 - val_loss: 1.3107 - val_acc: 0.4836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "igkQTLIDvvsG"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OehTYDa_rd8F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "47d1fe36-f4ce-4921-88e2-5372e3818d99"
      },
      "source": [
        "loss, acc = model.evaluate(testing_ds)\n",
        "wandb.log({'Test Accuracy': round(acc*100, 2)})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 1s 285ms/step - loss: 1.3107 - acc: 0.4836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "966mDKFhqsrk"
      },
      "source": [
        "# Training Linear Classifier with Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wP6P4VcJvbDQ"
      },
      "source": [
        "#### Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hACfOEyQnk4r",
        "colab": {}
      },
      "source": [
        "# Configs\n",
        "CROP_SIZE = 224\n",
        "MIN_SCALE = 0.5\n",
        "MAX_SCALE = 1.\n",
        "\n",
        "# Experimental options\n",
        "options = tf.data.Options()\n",
        "options.experimental_optimization.noop_elimination = True\n",
        "options.experimental_optimization.map_vectorization.enabled = True\n",
        "options.experimental_optimization.apply_default_optimizations = True\n",
        "options.experimental_deterministic = False\n",
        "options.experimental_threading.max_intra_op_parallelism = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hU2OZh1oTFaN",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def scale_image(image, label):\n",
        "\timage = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\treturn (image, label)\n",
        "\n",
        "@tf.function\n",
        "def random_apply(func, x, p):\n",
        "\treturn tf.cond(\n",
        "\t\ttf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "\t\t\t\ttf.cast(p, tf.float32)),\n",
        "\t\tlambda: func(x),\n",
        "\t\tlambda: x)\n",
        " \n",
        "@tf.function\n",
        "def random_resize_crop(image, label):\n",
        "  # Conditional resizing\n",
        "  image = tf.image.resize(image, (260, 260))\n",
        "  # Get the crop size for given min and max scale\n",
        "  size = tf.random.uniform(shape=(1,), minval=MIN_SCALE*260,\n",
        "\t\t          maxval=MAX_SCALE*260, dtype=tf.float32)\n",
        "  size = tf.cast(size, tf.int32)[0]\n",
        "  # Get the crop from the image\n",
        "  crop = tf.image.random_crop(image, (size,size,3))\n",
        "  crop_resize = tf.image.resize(crop, (CROP_SIZE, CROP_SIZE))\n",
        "  \n",
        "  return crop_resize, label\n",
        "\n",
        "@tf.function\n",
        "def tie_together(image, label):\n",
        "  # Scale the pixel values\n",
        "  image, label = scale_image(image , label)\n",
        "  # random horizontal flip\n",
        "  image = random_apply(tf.image.random_flip_left_right, image, p=0.5)\n",
        "  # Random resized crops\n",
        "  image, label = random_resize_crop(image, label)\n",
        "  \n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MLzlomx_d2iO",
        "colab": {}
      },
      "source": [
        "trainloader = (\n",
        "\ttrain_ds\n",
        "\t.shuffle(1024)\n",
        "\t.map(tie_together, num_parallel_calls=AUTO)\n",
        "\t.batch(BATCH_SIZE)\n",
        "\t.prefetch(AUTO)\n",
        ")\n",
        "\n",
        "trainloader = trainloader.with_options(options)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FyG-NSONve1P"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pat13QzdtsL3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bfa251e8-c9f3-46e7-8d80-64f7ba1c1301"
      },
      "source": [
        "# get model and compile\n",
        "tf.keras.backend.clear_session()\n",
        "model = get_linear_classifier(alpha=1e-6)\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer=\"adam\")\n",
        "\n",
        "# initialize wandb run\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train \n",
        "history = model.fit(training_ds,\n",
        "                 validation_data=(testing_ds),\n",
        "                 epochs=100,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "functional_1 (Functional)    (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 10245     \n",
            "=================================================================\n",
            "Total params: 23,597,957\n",
            "Trainable params: 10,245\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/2m2knt7o\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/2m2knt7o</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 12s 911ms/step - loss: 2.3080 - acc: 0.2144 - val_loss: 1.8739 - val_acc: 0.2618\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.7829 - acc: 0.2455 - val_loss: 1.6803 - val_acc: 0.2764\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 12s 906ms/step - loss: 1.6495 - acc: 0.2500 - val_loss: 1.6601 - val_acc: 0.2400\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 12s 892ms/step - loss: 1.6055 - acc: 0.2923 - val_loss: 1.6185 - val_acc: 0.2655\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 11s 872ms/step - loss: 1.5808 - acc: 0.2875 - val_loss: 1.5956 - val_acc: 0.3018\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 11s 867ms/step - loss: 1.5663 - acc: 0.3010 - val_loss: 1.5863 - val_acc: 0.2873\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 11s 867ms/step - loss: 1.5545 - acc: 0.3128 - val_loss: 1.5669 - val_acc: 0.3036\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 11s 876ms/step - loss: 1.5412 - acc: 0.3215 - val_loss: 1.5554 - val_acc: 0.3109\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 12s 885ms/step - loss: 1.5299 - acc: 0.3288 - val_loss: 1.5482 - val_acc: 0.3200\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.5204 - acc: 0.3317 - val_loss: 1.5392 - val_acc: 0.3218\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.5111 - acc: 0.3397 - val_loss: 1.5310 - val_acc: 0.3291\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 11s 874ms/step - loss: 1.5017 - acc: 0.3471 - val_loss: 1.5238 - val_acc: 0.3364\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 11s 883ms/step - loss: 1.4925 - acc: 0.3522 - val_loss: 1.5177 - val_acc: 0.3400\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 11s 872ms/step - loss: 1.4838 - acc: 0.3590 - val_loss: 1.5119 - val_acc: 0.3418\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 11s 874ms/step - loss: 1.4753 - acc: 0.3644 - val_loss: 1.5066 - val_acc: 0.3455\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 1.4669 - acc: 0.3692 - val_loss: 1.5016 - val_acc: 0.3545\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 11s 883ms/step - loss: 1.4586 - acc: 0.3728 - val_loss: 1.4969 - val_acc: 0.3636\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 1.4506 - acc: 0.3776 - val_loss: 1.4923 - val_acc: 0.3618\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.4426 - acc: 0.3811 - val_loss: 1.4879 - val_acc: 0.3636\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 11s 883ms/step - loss: 1.4347 - acc: 0.3881 - val_loss: 1.4836 - val_acc: 0.3691\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 11s 881ms/step - loss: 1.4270 - acc: 0.3939 - val_loss: 1.4793 - val_acc: 0.3691\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 11s 876ms/step - loss: 1.4194 - acc: 0.3958 - val_loss: 1.4750 - val_acc: 0.3673\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.4120 - acc: 0.4000 - val_loss: 1.4708 - val_acc: 0.3673\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 11s 874ms/step - loss: 1.4048 - acc: 0.4042 - val_loss: 1.4666 - val_acc: 0.3745\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 1.3977 - acc: 0.4090 - val_loss: 1.4625 - val_acc: 0.3782\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 11s 876ms/step - loss: 1.3909 - acc: 0.4154 - val_loss: 1.4585 - val_acc: 0.3800\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.3842 - acc: 0.4183 - val_loss: 1.4546 - val_acc: 0.3818\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 12s 886ms/step - loss: 1.3777 - acc: 0.4231 - val_loss: 1.4508 - val_acc: 0.3873\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 12s 887ms/step - loss: 1.3715 - acc: 0.4288 - val_loss: 1.4472 - val_acc: 0.3891\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.3654 - acc: 0.4330 - val_loss: 1.4437 - val_acc: 0.3945\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 11s 883ms/step - loss: 1.3595 - acc: 0.4353 - val_loss: 1.4403 - val_acc: 0.3964\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 12s 889ms/step - loss: 1.3538 - acc: 0.4394 - val_loss: 1.4371 - val_acc: 0.3964\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 12s 898ms/step - loss: 1.3482 - acc: 0.4423 - val_loss: 1.4340 - val_acc: 0.4018\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 11s 883ms/step - loss: 1.3428 - acc: 0.4465 - val_loss: 1.4310 - val_acc: 0.4018\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.3376 - acc: 0.4490 - val_loss: 1.4282 - val_acc: 0.4091\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 12s 888ms/step - loss: 1.3326 - acc: 0.4558 - val_loss: 1.4256 - val_acc: 0.4127\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 12s 890ms/step - loss: 1.3276 - acc: 0.4596 - val_loss: 1.4230 - val_acc: 0.4127\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 12s 892ms/step - loss: 1.3229 - acc: 0.4628 - val_loss: 1.4206 - val_acc: 0.4145\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 11s 883ms/step - loss: 1.3182 - acc: 0.4673 - val_loss: 1.4183 - val_acc: 0.4182\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 11s 883ms/step - loss: 1.3137 - acc: 0.4692 - val_loss: 1.4161 - val_acc: 0.4255\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 11s 883ms/step - loss: 1.3093 - acc: 0.4737 - val_loss: 1.4140 - val_acc: 0.4273\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.3050 - acc: 0.4763 - val_loss: 1.4119 - val_acc: 0.4236\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.3009 - acc: 0.4801 - val_loss: 1.4099 - val_acc: 0.4255\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.2968 - acc: 0.4840 - val_loss: 1.4080 - val_acc: 0.4273\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 12s 888ms/step - loss: 1.2929 - acc: 0.4875 - val_loss: 1.4061 - val_acc: 0.4291\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 12s 885ms/step - loss: 1.2890 - acc: 0.4891 - val_loss: 1.4042 - val_acc: 0.4309\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 12s 893ms/step - loss: 1.2852 - acc: 0.4904 - val_loss: 1.4023 - val_acc: 0.4345\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 11s 883ms/step - loss: 1.2815 - acc: 0.4923 - val_loss: 1.4005 - val_acc: 0.4345\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 11s 884ms/step - loss: 1.2779 - acc: 0.4936 - val_loss: 1.3986 - val_acc: 0.4345\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 11s 881ms/step - loss: 1.2743 - acc: 0.4965 - val_loss: 1.3967 - val_acc: 0.4327\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.2708 - acc: 0.5006 - val_loss: 1.3948 - val_acc: 0.4327\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 11s 885ms/step - loss: 1.2673 - acc: 0.5016 - val_loss: 1.3928 - val_acc: 0.4327\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.2638 - acc: 0.5016 - val_loss: 1.3909 - val_acc: 0.4327\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 11s 879ms/step - loss: 1.2604 - acc: 0.5029 - val_loss: 1.3888 - val_acc: 0.4327\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 11s 879ms/step - loss: 1.2571 - acc: 0.5054 - val_loss: 1.3868 - val_acc: 0.4345\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 11s 883ms/step - loss: 1.2537 - acc: 0.5083 - val_loss: 1.3847 - val_acc: 0.4364\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.2503 - acc: 0.5099 - val_loss: 1.3825 - val_acc: 0.4418\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 12s 885ms/step - loss: 1.2470 - acc: 0.5115 - val_loss: 1.3804 - val_acc: 0.4418\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.2437 - acc: 0.5131 - val_loss: 1.3782 - val_acc: 0.4418\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 1.2404 - acc: 0.5135 - val_loss: 1.3760 - val_acc: 0.4473\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 11s 881ms/step - loss: 1.2371 - acc: 0.5163 - val_loss: 1.3738 - val_acc: 0.4455\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 11s 883ms/step - loss: 1.2338 - acc: 0.5173 - val_loss: 1.3716 - val_acc: 0.4455\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 1.2305 - acc: 0.5189 - val_loss: 1.3695 - val_acc: 0.4455\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 11s 883ms/step - loss: 1.2273 - acc: 0.5202 - val_loss: 1.3674 - val_acc: 0.4491\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.2240 - acc: 0.5205 - val_loss: 1.3653 - val_acc: 0.4491\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.2208 - acc: 0.5228 - val_loss: 1.3632 - val_acc: 0.4455\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 12s 889ms/step - loss: 1.2177 - acc: 0.5266 - val_loss: 1.3612 - val_acc: 0.4455\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 11s 881ms/step - loss: 1.2145 - acc: 0.5285 - val_loss: 1.3592 - val_acc: 0.4455\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 12s 887ms/step - loss: 1.2114 - acc: 0.5288 - val_loss: 1.3573 - val_acc: 0.4436\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 12s 886ms/step - loss: 1.2083 - acc: 0.5304 - val_loss: 1.3554 - val_acc: 0.4436\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 11s 876ms/step - loss: 1.2052 - acc: 0.5327 - val_loss: 1.3535 - val_acc: 0.4436\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.2022 - acc: 0.5356 - val_loss: 1.3518 - val_acc: 0.4455\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 11s 881ms/step - loss: 1.1991 - acc: 0.5381 - val_loss: 1.3500 - val_acc: 0.4455\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.1962 - acc: 0.5401 - val_loss: 1.3483 - val_acc: 0.4491\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 11s 881ms/step - loss: 1.1932 - acc: 0.5429 - val_loss: 1.3467 - val_acc: 0.4473\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 12s 888ms/step - loss: 1.1903 - acc: 0.5449 - val_loss: 1.3450 - val_acc: 0.4473\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 11s 881ms/step - loss: 1.1874 - acc: 0.5465 - val_loss: 1.3435 - val_acc: 0.4473\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 1.1845 - acc: 0.5478 - val_loss: 1.3420 - val_acc: 0.4491\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 11s 873ms/step - loss: 1.1817 - acc: 0.5506 - val_loss: 1.3405 - val_acc: 0.4527\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 11s 881ms/step - loss: 1.1789 - acc: 0.5522 - val_loss: 1.3390 - val_acc: 0.4527\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.1761 - acc: 0.5535 - val_loss: 1.3376 - val_acc: 0.4545\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.1734 - acc: 0.5551 - val_loss: 1.3363 - val_acc: 0.4582\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 11s 880ms/step - loss: 1.1706 - acc: 0.5561 - val_loss: 1.3349 - val_acc: 0.4582\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 12s 886ms/step - loss: 1.1679 - acc: 0.5574 - val_loss: 1.3336 - val_acc: 0.4600\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 11s 879ms/step - loss: 1.1653 - acc: 0.5593 - val_loss: 1.3324 - val_acc: 0.4618\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 12s 896ms/step - loss: 1.1626 - acc: 0.5609 - val_loss: 1.3312 - val_acc: 0.4636\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.1600 - acc: 0.5628 - val_loss: 1.3300 - val_acc: 0.4636\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 11s 881ms/step - loss: 1.1574 - acc: 0.5635 - val_loss: 1.3288 - val_acc: 0.4636\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 11s 879ms/step - loss: 1.1548 - acc: 0.5657 - val_loss: 1.3277 - val_acc: 0.4636\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 11s 873ms/step - loss: 1.1523 - acc: 0.5676 - val_loss: 1.3266 - val_acc: 0.4636\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 11s 876ms/step - loss: 1.1498 - acc: 0.5686 - val_loss: 1.3255 - val_acc: 0.4636\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 1.1473 - acc: 0.5702 - val_loss: 1.3244 - val_acc: 0.4636\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 11s 884ms/step - loss: 1.1448 - acc: 0.5715 - val_loss: 1.3234 - val_acc: 0.4636\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 11s 884ms/step - loss: 1.1423 - acc: 0.5734 - val_loss: 1.3224 - val_acc: 0.4618\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 11s 882ms/step - loss: 1.1399 - acc: 0.5740 - val_loss: 1.3214 - val_acc: 0.4618\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 11s 877ms/step - loss: 1.1375 - acc: 0.5760 - val_loss: 1.3205 - val_acc: 0.4618\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 1.1351 - acc: 0.5782 - val_loss: 1.3196 - val_acc: 0.4618\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 12s 885ms/step - loss: 1.1327 - acc: 0.5782 - val_loss: 1.3187 - val_acc: 0.4636\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 11s 884ms/step - loss: 1.1304 - acc: 0.5795 - val_loss: 1.3178 - val_acc: 0.4673\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 12s 887ms/step - loss: 1.1280 - acc: 0.5824 - val_loss: 1.3169 - val_acc: 0.4691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eOz5DRHYv10d"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_mlWQCf-vqxn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3fbe0429-67b2-47c8-c9f7-1f8b70755409"
      },
      "source": [
        "loss, acc = model.evaluate(testing_ds)\n",
        "wandb.log({'Test Accuracy': round(acc*100, 2)})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 1s 284ms/step - loss: 1.3169 - acc: 0.4691\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}